{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7321687,"sourceType":"datasetVersion","datasetId":4249023},{"sourceId":7390759,"sourceType":"datasetVersion","datasetId":4296369}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install yt-dlp spleeter -q","metadata":{"_uuid":"874b103f-5550-4ad2-8d22-73e8e98eb196","_cell_guid":"a1625bc1-c21b-4496-b0d2-8f1fc3d19c74","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T08:27:31.157142Z","iopub.execute_input":"2024-01-29T08:27:31.157848Z","iopub.status.idle":"2024-01-29T08:28:58.300986Z","shell.execute_reply.started":"2024-01-29T08:27:31.157817Z","shell.execute_reply":"2024-01-29T08:28:58.299936Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.12.1 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.19.6 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask 2023.12.0 requires click>=8.1, but you have click 7.1.2 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndistributed 2023.12.0 requires click>=8.0, but you have click 7.1.2 which is incompatible.\nfiona 1.9.5 requires click~=8.0, but you have click 7.1.2 which is incompatible.\nfitter 1.6.0 requires click<9.0.0,>=8.1.6, but you have click 7.1.2 which is incompatible.\nfitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 1.5.3 which is incompatible.\nflask 3.0.0 requires click>=8.1.3, but you have click 7.1.2 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.12.2 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-pubsub 2.18.3 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\nkfp 2.0.1 requires click<9,>=8.0.0, but you have click 7.1.2 which is incompatible.\nkfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nonnx 1.15.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.5.0 requires tensorflow~=2.13.0, but you have tensorflow 2.9.3 which is incompatible.\ntensorflow-serving-api 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.13.0 requires tensorflow<3,>=2.13.0, but you have tensorflow 2.9.3 which is incompatible.\ntensorflow-text 2.13.0 requires tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.9.3 which is incompatible.\ntensorflowjs 4.14.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\ntensorflowjs 4.14.0 requires tensorflow<3,>=2.13.0, but you have tensorflow 2.9.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport subprocess\nimport contextlib\nimport logging\nfrom functools import wraps\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nfrom sklearn.cluster import KMeans\n\nimport librosa\nimport yt_dlp\nfrom spleeter.separator import Separator\nimport ffmpeg\n\nimport torch\nimport torchaudio\nfrom transformers import AutoModelForAudioClassification, ASTFeatureExtractor","metadata":{"_uuid":"cbc7da9d-ed87-4781-acab-e0f064551462","_cell_guid":"79616bb2-fec4-4c9f-9aed-5d25b8f504ca","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T08:28:58.302980Z","iopub.execute_input":"2024-01-29T08:28:58.303281Z","iopub.status.idle":"2024-01-29T08:29:05.469430Z","shell.execute_reply.started":"2024-01-29T08:28:58.303255Z","shell.execute_reply":"2024-01-29T08:29:05.468594Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def suppress_output(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        # Redirect stdout and logging to os.devnull\n        with open(os.devnull, 'w') as fnull:\n            with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n                # Configure logging to use a NullHandler\n                null_handler = logging.NullHandler()\n                root_logger = logging.getLogger()\n                original_handlers = root_logger.handlers.copy()\n                root_logger.handlers = [null_handler]\n                try:\n                    result = func(*args, **kwargs)\n                finally:\n                    # Restore the original logging handlers\n                    root_logger.handlers = original_handlers\n        return result\n    return wrapper","metadata":{"_uuid":"885b28b5-a337-4fa9-bb41-b4fef004d71c","_cell_guid":"c0c99f87-bdf4-4466-b5c2-8373f5f03b71","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T08:29:05.470599Z","iopub.execute_input":"2024-01-29T08:29:05.471309Z","iopub.status.idle":"2024-01-29T08:29:05.478232Z","shell.execute_reply.started":"2024-01-29T08:29:05.471271Z","shell.execute_reply":"2024-01-29T08:29:05.477096Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#@suppress_output\ndef download_youtube_audio(url):\n    ydl_opts = {\n        'format': 'bestaudio',\n        'format_sort': ['+size'],\n        'outtmpl': '%(id)s.%(ext)s',\n        'postprocessors': [{\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': 'wav',  \n        }]\n    }\n\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n        ydl.download([url])\n        video_info = ydl.extract_info(url, download=False)\n    \n    video_path_local = Path(f\"{video_info['id']}.wav\")\n    \n    return video_path_local","metadata":{"_uuid":"ad6ff837-3a42-4bc1-a820-7eaf465c2a13","_cell_guid":"9492610c-5d60-4032-8a29-ad9730634f86","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T08:29:05.480896Z","iopub.execute_input":"2024-01-29T08:29:05.481242Z","iopub.status.idle":"2024-01-29T08:29:05.491385Z","shell.execute_reply.started":"2024-01-29T08:29:05.481209Z","shell.execute_reply":"2024-01-29T08:29:05.490621Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef slice_wav_by_length(input_file, outfile_name_pattern, desired_length=600):\n    # FFmpeg command to split the WAV file into 10-minute segments\n    command = [\n        'ffmpeg',\n        '-hide_banner',  # Added to hide FFmpeg banner\n        '-loglevel', 'error',  # Set log level to error\n        '-i', input_file,\n        '-f', 'segment',\n        '-segment_time', str(desired_length),\n        '-c', 'copy',\n        f\"{outfile_name_pattern}%03d.wav\"\n    ]\n\n    # Run the FFmpeg command\n    subprocess.run(command)","metadata":{"_uuid":"3bdcb9b9-b27e-4e95-9d82-24f66773eb52","_cell_guid":"5c95b893-79e4-43d8-932c-1552c2ff05e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T08:29:05.492369Z","iopub.execute_input":"2024-01-29T08:29:05.492687Z","iopub.status.idle":"2024-01-29T08:29:05.504144Z","shell.execute_reply.started":"2024-01-29T08:29:05.492663Z","shell.execute_reply":"2024-01-29T08:29:05.503295Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef seperate_vocal_and_accompanies(separator, output_paths):\n    output_directory = 'output'\n    os.makedirs(output_directory, exist_ok=True)\n    \n    for file_path in tqdm(output_paths, desc=\"Processing files\"):\n        output_file_path = os.path.join(output_directory, os.path.basename(file_path))\n        separator.separate_to_file(file_path, output_file_path)","metadata":{"_uuid":"a96c161d-9c80-4e16-93f5-ed24a729c206","_cell_guid":"f3660bd1-60de-4330-9e3f-baf6adf3de91","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T08:29:05.505128Z","iopub.execute_input":"2024-01-29T08:29:05.505446Z","iopub.status.idle":"2024-01-29T08:29:05.518617Z","shell.execute_reply.started":"2024-01-29T08:29:05.505397Z","shell.execute_reply":"2024-01-29T08:29:05.517853Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_filepaths_with_string_and_extension(\n    root_directory='.', target_string='', extension=''):\n    return sorted([os.path.abspath(os.path.join(root, file)) \n         for root, _, files in os.walk(root_directory)\n         for file in files \n         if target_string in file and (not extension or file.endswith(extension))]\n    )","metadata":{"_uuid":"59c4f791-3aec-43c1-b348-97b2425a6aa0","_cell_guid":"bfb39bec-3dff-4d7a-a766-2b5a443b0158","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T08:29:05.519774Z","iopub.execute_input":"2024-01-29T08:29:05.520048Z","iopub.status.idle":"2024-01-29T08:29:05.528358Z","shell.execute_reply.started":"2024-01-29T08:29:05.520021Z","shell.execute_reply":"2024-01-29T08:29:05.527594Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def load_and_slice_audio(vocal_paths, slice_duration=10):\n    all_samples = []\n    all_sampling_rates = []\n\n    for path in tqdm(vocal_paths):\n        waveform, sampling_rate = torchaudio.load(path)\n        waveform = waveform.squeeze().numpy()\n\n        num_slices = waveform.shape[-1] // (sampling_rate * slice_duration)\n\n        samples = [\n            torch.from_numpy(\n                waveform[:, i * sampling_rate * slice_duration : (i + 1) * sampling_rate * slice_duration]\n            )\n            for i in range(num_slices)\n        ]\n\n        all_samples.extend(samples)\n        all_sampling_rates.extend([sampling_rate] * num_slices)\n\n    return all_samples, all_sampling_rates","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.529313Z","iopub.execute_input":"2024-01-29T08:29:05.529611Z","iopub.status.idle":"2024-01-29T08:29:05.539804Z","shell.execute_reply.started":"2024-01-29T08:29:05.529564Z","shell.execute_reply":"2024-01-29T08:29:05.538948Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_common_sampling_rate(sampling_rates):\n    if len(set(sampling_rates)) == 1:\n        return int(sampling_rates[0])\n    else:\n        raise ValueError(\"All sampling rates should be the same.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.540884Z","iopub.execute_input":"2024-01-29T08:29:05.541158Z","iopub.status.idle":"2024-01-29T08:29:05.551649Z","shell.execute_reply.started":"2024-01-29T08:29:05.541134Z","shell.execute_reply":"2024-01-29T08:29:05.550916Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def predict_samples(model, feature_extractor, monofied_samples, sampling_rate, device):\n    result = []\n    raw_outputs = []\n\n    for i, sample in tqdm(enumerate(monofied_samples), total=len(monofied_samples), desc=\"Processing samples\"):\n        inputs = feature_extractor(\n            sample, feature_size=2, sampling_rate=sampling_rate, \n            padding=\"max_length\", return_tensors=\"pt\"\n        )\n        \n        input_values = inputs.input_values.to(device)\n\n        with torch.no_grad():\n            outputs = model(input_values)\n            predicted_labels = model.config.id2label[outputs.logits.argmax(-1).item()]\n            result.append([i, predicted_labels])\n            raw_outputs.append(outputs)\n\n    return result, raw_outputs","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.555867Z","iopub.execute_input":"2024-01-29T08:29:05.556188Z","iopub.status.idle":"2024-01-29T08:29:05.569244Z","shell.execute_reply.started":"2024-01-29T08:29:05.556161Z","shell.execute_reply":"2024-01-29T08:29:05.568386Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def create_dataframe(predictions, time_window_length):\n    df = pd.DataFrame(predictions, columns=['index', 'class'])\n    df['start'] = df['index'].apply(lambda x: seconds_to_hhmmss(x*time_window_length))\n    df['end'] = df['index'].apply(lambda x: seconds_to_hhmmss((x+1)*time_window_length))\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.570446Z","iopub.execute_input":"2024-01-29T08:29:05.571171Z","iopub.status.idle":"2024-01-29T08:29:05.579348Z","shell.execute_reply.started":"2024-01-29T08:29:05.571136Z","shell.execute_reply":"2024-01-29T08:29:05.578497Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def audio_analyzer(file_paths, model, device, slice_duration):\n    sliced_samples, sampling_rates = load_and_slice_audio(file_paths, slice_duration)\n    monofied_samples = [torch.mean(x, dim=0) for x in sliced_samples]\n    sampling_rate = get_common_sampling_rate(sampling_rates)\n\n    feature_extractor = ASTFeatureExtractor(\n        sampling_rate=sampling_rate, do_normalize=True\n    )\n\n    predictions, raw_outputs = predict_samples(\n        model, feature_extractor, monofied_samples, sampling_rate, device\n    )\n\n    result_df = create_dataframe(predictions, time_window_length=slice_duration)\n\n    return result_df, raw_outputs","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.580506Z","iopub.execute_input":"2024-01-29T08:29:05.581442Z","iopub.status.idle":"2024-01-29T08:29:05.590639Z","shell.execute_reply.started":"2024-01-29T08:29:05.581409Z","shell.execute_reply":"2024-01-29T08:29:05.589912Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def class_manipulator_old(input_df):\n    # Create a copy of the input DataFrame to avoid modifying the original\n    df = input_df.copy()\n\n    # Binarize the 'class' column\n    df['binarized_class'] = df['class'].apply(\n        lambda x: 0 if (x in ['Speech','Tick', 'Clicking', ]) else 1\n    )\n\n    # Create the 'group' column\n    df['group'] = (df['binarized_class'] != df['binarized_class'].shift()).cumsum()\n\n    # Group the DataFrame by the new 'group' column\n    grouped_df = df.groupby(['binarized_class', 'group']).agg(\n        start=('start', 'first'),\n        end=('end', 'last'),\n        class_value=('class', 'first')\n    ).reset_index(drop=True)\n\n    # Filter out unwanted classes and sort by 'start'\n    intermediate_df = grouped_df[\n        ~grouped_df['class_value'].isin(['Speech','Tick', 'Clicking',])\n    ].sort_values('start').reset_index(drop=True)\n\n    return intermediate_df","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.591790Z","iopub.execute_input":"2024-01-29T08:29:05.592519Z","iopub.status.idle":"2024-01-29T08:29:05.602753Z","shell.execute_reply.started":"2024-01-29T08:29:05.592495Z","shell.execute_reply":"2024-01-29T08:29:05.601918Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def class_manipulator(input_df, singing_like_classes):\n    \n    def _get_most_frequent_with_fallback(x):\n        modes = x.mode()\n        if not modes.empty:\n            if any(mode in singing_like_classes for mode in modes):\n                return 'Singing'\n        return None #'Speech'\n    \n    # Create a copy of the input DataFrame to avoid modifying the original\n    df = input_df.copy()\n    \n    # Binarize the 'class' column\n    df['binarized_class'] = df['class'].apply(\n        lambda x : 1 if (x in singing_like_classes) else 0\n    )\n\n    # Create the 'group' column\n    df['group'] = (df['binarized_class'] != df['binarized_class'].shift()).cumsum()\n\n    # Group the DataFrame by the new 'group' column\n    grouped_df = df.groupby(['binarized_class', 'group']).agg(\n        start=('start', 'first'),\n        end=('end', 'last'),\n        class_value=('class', _get_most_frequent_with_fallback) \n    ).reset_index(drop=True).dropna()\n\n    return grouped_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.603865Z","iopub.execute_input":"2024-01-29T08:29:05.604182Z","iopub.status.idle":"2024-01-29T08:29:05.618453Z","shell.execute_reply.started":"2024-01-29T08:29:05.604158Z","shell.execute_reply":"2024-01-29T08:29:05.617597Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def group_same_songs(input_df, interval_threshold, duration_threshold):\n    \n    df = input_df.copy()\n\n    df['start'] = pd.to_datetime(df['start'])\n    df['end'] = pd.to_datetime(df['end'])\n\n    df['group'] = 0\n\n    for i in range(1, len(df)):\n        if (df['start'][i] - df['end'][i - 1]).total_seconds() <= interval_threshold:\n            df.at[i, 'group'] = df.at[i - 1, 'group']\n        else:\n            df.at[i, 'group'] = df.at[i - 1, 'group'] + 1\n\n    grouped_df = df.groupby('group')\n\n    for group, group_df in grouped_df:\n        duration = (group_df['end'].max() - group_df['start'].min()).total_seconds()\n        if duration < duration_threshold:\n            df = df[df['group'] != group]\n\n    df = df.drop(columns=['class_value'])\n\n    df = df.groupby('group').agg({'start':'first', 'end':'last'})\n\n    df['start'] = df['start'].apply(lambda x:x.strftime('%H:%M:%S'))\n    df['end'] = df['end'].apply(lambda x:x.strftime('%H:%M:%S'))\n    \n    return df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.619586Z","iopub.execute_input":"2024-01-29T08:29:05.620083Z","iopub.status.idle":"2024-01-29T08:29:05.630876Z","shell.execute_reply.started":"2024-01-29T08:29:05.620057Z","shell.execute_reply":"2024-01-29T08:29:05.630018Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def mfcc_from_accompanies(accompanies_paths, slice_duration=5):\n\n    sliced_samples, sampling_rates = load_and_slice_audio(accompanies_paths, slice_duration)\n    monofied_samples = [torch.mean(x, dim=0) for x in sliced_samples]\n    sampling_rate = get_common_sampling_rate(sampling_rates)\n    mfccs = [librosa.feature.mfcc(y=y.numpy(), sr=sampling_rate, n_mfcc=13) \n             for y in monofied_samples]\n    \n    return mfccs","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.631781Z","iopub.execute_input":"2024-01-29T08:29:05.632098Z","iopub.status.idle":"2024-01-29T08:29:05.645450Z","shell.execute_reply.started":"2024-01-29T08:29:05.632069Z","shell.execute_reply":"2024-01-29T08:29:05.644480Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def cluster_mfccs(mfccs):\n    full_flattens = [x.flatten() for x in mfccs]\n    kmeans = KMeans(n_clusters=2, n_init=2)  # You can choose the number of clusters\n    kmeans.fit(full_flattens)\n    cluster_labels = kmeans.labels_\n\n    indices = np.arange(len(cluster_labels))\n    temp_df = create_dataframe(np.vstack((indices, cluster_labels)).T, time_window_length=5)\n\n    value_counts = temp_df['class'].value_counts()\n    major_value = value_counts.idxmax()\n    minor_value = value_counts.idxmin()\n\n    label_mapping = {major_value: 'Speech', minor_value: 'Singing'}\n    temp_df['class_value'] = temp_df['class'].map(label_mapping)\n\n    return temp_df[temp_df['class_value']=='Singing'].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.646664Z","iopub.execute_input":"2024-01-29T08:29:05.646982Z","iopub.status.idle":"2024-01-29T08:29:05.657089Z","shell.execute_reply.started":"2024-01-29T08:29:05.646952Z","shell.execute_reply":"2024-01-29T08:29:05.656186Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def seconds_to_hhmmss(total_seconds):\n    m, s = divmod(total_seconds, 60)\n    h, m = divmod(m, 60)\n    return f\"{h:02d}:{m:02d}:{s:02d}\"\n        \ndef hhmmss_to_seconds(hms):\n    h, m, s = map(int, hms.split(':'))\n    return h * 3600 + m * 60 + s","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.658097Z","iopub.execute_input":"2024-01-29T08:29:05.659249Z","iopub.status.idle":"2024-01-29T08:29:05.671200Z","shell.execute_reply.started":"2024-01-29T08:29:05.659223Z","shell.execute_reply":"2024-01-29T08:29:05.670372Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def check_overlap(interval1_start, interval1_end, interval2_start, interval2_end):\n    return (interval1_start <= interval2_end and interval1_end >= interval2_start) or \\\n           (interval2_start <= interval1_end and interval2_end >= interval1_start)\n\ndef find_and_filter_overlapping_timestamps(accompanies_df, vocal_df):\n    unique_overlapping_timestamps = []\n\n    for _, row1 in accompanies_df.iterrows():\n        for _, row2 in vocal_df.iterrows():\n            start1_seconds = hhmmss_to_seconds(row1['start'])\n            end1_seconds = hhmmss_to_seconds(row1['end'])\n            start2_seconds = hhmmss_to_seconds(row2['start'])\n            end2_seconds = hhmmss_to_seconds(row2['end'])\n\n            # Check for overlap\n            if check_overlap(start1_seconds, end1_seconds, start2_seconds, end2_seconds):\n                overlap_start = min(start1_seconds, start2_seconds)\n                overlap_end = max(end1_seconds, end2_seconds)\n                overlapping_timestamp = {\n                    'start': seconds_to_hhmmss(overlap_start),\n                    'end': seconds_to_hhmmss(overlap_end)\n                }\n                if overlapping_timestamp not in unique_overlapping_timestamps:\n                    unique_overlapping_timestamps.append(overlapping_timestamp)\n\n    # Filter out redundant overlaps\n    filtered_overlapping_timestamps = [\n        overlap for overlap in unique_overlapping_timestamps\n        if all(\n            not (\n                hhmmss_to_seconds(overlap['start']) >= hhmmss_to_seconds(other_overlap['start']) and\n                hhmmss_to_seconds(overlap['end']) <= hhmmss_to_seconds(other_overlap['end'])\n            )\n            for other_overlap in unique_overlapping_timestamps\n            if overlap != other_overlap\n        )\n    ]\n\n    merged_result = pd.DataFrame(filtered_overlapping_timestamps)\n\n    return merged_result","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.672236Z","iopub.execute_input":"2024-01-29T08:29:05.674782Z","iopub.status.idle":"2024-01-29T08:29:05.685793Z","shell.execute_reply.started":"2024-01-29T08:29:05.674757Z","shell.execute_reply":"2024-01-29T08:29:05.684876Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"!rm -rf ./output\n\noutput_filename_pattern = 'noa'\nroot_dir = '.'  \nyoutube_url = 'https://www.youtube.com/watch?v=uvuDBBDUnEs'\n\nseparator = Separator(\"spleeter:2stems\")\n\nslice_wav_by_length(download_youtube_audio(youtube_url), output_filename_pattern)\n\nwav_slice_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = output_filename_pattern, extension='wav'\n)\n\nseperate_vocal_and_accompanies(separator, wav_slice_paths)\n\naccompanies_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'accompaniment', extension='wav'\n)\n\nvocal_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'vocal', extension='wav'\n)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel = AutoModelForAudioClassification.from_pretrained(\n    \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:29:05.686882Z","iopub.execute_input":"2024-01-29T08:29:05.687222Z","iopub.status.idle":"2024-01-29T08:51:37.004378Z","shell.execute_reply.started":"2024-01-29T08:29:05.687191Z","shell.execute_reply":"2024-01-29T08:51:37.003396Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[youtube] Extracting URL: https://www.youtube.com/watch?v=uvuDBBDUnEs\n[youtube] uvuDBBDUnEs: Downloading webpage\n[youtube] uvuDBBDUnEs: Downloading ios player API JSON\n[youtube] uvuDBBDUnEs: Downloading android player API JSON\n[youtube] uvuDBBDUnEs: Downloading m3u8 information\n[youtube] uvuDBBDUnEs: Downloading m3u8 information\n[youtube] uvuDBBDUnEs: Downloading MPD manifest\n[youtube] uvuDBBDUnEs: Downloading m3u8 information\n[youtube] uvuDBBDUnEs: Downloading MPD manifest\n[info] uvuDBBDUnEs: Downloading 1 format(s): 140\n[dashsegments] Total fragments: 4208\n[download] Destination: uvuDBBDUnEs.m4a\n[download] 100% of   86.84MiB in 00:21:22 at 69.36KiB/s                    \n[FixupM4a] Correcting container of \"uvuDBBDUnEs.m4a\"\n[ExtractAudio] Destination: uvuDBBDUnEs.wav\nDeleting original file uvuDBBDUnEs.m4a (pass -k to keep)\n[youtube] Extracting URL: https://www.youtube.com/watch?v=uvuDBBDUnEs\n[youtube] uvuDBBDUnEs: Downloading webpage\n[youtube] uvuDBBDUnEs: Downloading ios player API JSON\n[youtube] uvuDBBDUnEs: Downloading android player API JSON\n[youtube] uvuDBBDUnEs: Downloading m3u8 information\n[youtube] uvuDBBDUnEs: Downloading m3u8 information\n[youtube] uvuDBBDUnEs: Downloading MPD manifest\n[youtube] uvuDBBDUnEs: Downloading m3u8 information\n[youtube] uvuDBBDUnEs: Downloading MPD manifest\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing files:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"484236b186b94b2dbf339b142cbc6d45"}},"metadata":{}},{"name":"stdout","text":"INFO:spleeter:File output/noa000.wav/noa000/vocals.wav written succesfully\nINFO:spleeter:File output/noa000.wav/noa000/accompaniment.wav written succesfully\nINFO:spleeter:File output/noa001.wav/noa001/vocals.wav written succesfully\nINFO:spleeter:File output/noa001.wav/noa001/accompaniment.wav written succesfully\nINFO:spleeter:File output/noa002.wav/noa002/vocals.wav written succesfully\nINFO:spleeter:File output/noa002.wav/noa002/accompaniment.wav written succesfully\nINFO:spleeter:File output/noa003.wav/noa003/vocals.wav written succesfully\nINFO:spleeter:File output/noa003.wav/noa003/accompaniment.wav written succesfully\nINFO:spleeter:File output/noa004.wav/noa004/vocals.wav written succesfully\nINFO:spleeter:File output/noa004.wav/noa004/accompaniment.wav written succesfully\nINFO:spleeter:File output/noa005.wav/noa005/vocals.wav written succesfully\nINFO:spleeter:File output/noa005.wav/noa005/accompaniment.wav written succesfully\nINFO:spleeter:File output/noa006.wav/noa006/vocals.wav written succesfully\nINFO:spleeter:File output/noa006.wav/noa006/accompaniment.wav written succesfully\nINFO:spleeter:File output/noa007.wav/noa007/vocals.wav written succesfully\nINFO:spleeter:File output/noa007.wav/noa007/accompaniment.wav written succesfully\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65d8ab104aed4a58919f6b41909037a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d9665045f1b4d6d98650ce3a031ca7c"}},"metadata":{}}]},{"cell_type":"code","source":"result_vocal, raw_outputs = audio_analyzer(\n    vocal_paths, model, device, slice_duration=5\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:51:37.005987Z","iopub.execute_input":"2024-01-29T08:51:37.006307Z","iopub.status.idle":"2024-01-29T08:52:40.454340Z","shell.execute_reply.started":"2024-01-29T08:51:37.006279Z","shell.execute_reply":"2024-01-29T08:52:40.453497Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5c5f1eed8464e4db57b56677b0832a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing samples:   0%|          | 0/840 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cce97b7509243a29f2acc0af136702a"}},"metadata":{}}]},{"cell_type":"code","source":"classes = model.config.id2label\nsinging_like_indices = [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 112, 113, 114, 116, 117, 118, 119, 120, 136, 254, 255, 266, 259, 268, 269, 271, 402, 496, 503,523, 526]\nsinging_like_classes = [classes.get(x) for x in singing_like_indices]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:52:40.455689Z","iopub.execute_input":"2024-01-29T08:52:40.456496Z","iopub.status.idle":"2024-01-29T08:52:40.462295Z","shell.execute_reply.started":"2024-01-29T08:52:40.456458Z","shell.execute_reply":"2024-01-29T08:52:40.461381Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"vocal_result = group_same_songs(\n    class_manipulator(result_vocal, singing_like_classes),\n    interval_threshold=10, duration_threshold=30\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:52:40.463646Z","iopub.execute_input":"2024-01-29T08:52:40.464217Z","iopub.status.idle":"2024-01-29T08:52:40.533402Z","shell.execute_reply.started":"2024-01-29T08:52:40.464184Z","shell.execute_reply":"2024-01-29T08:52:40.532368Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"mfccs = mfcc_from_accompanies(accompanies_paths, slice_duration=5)\naccompanies_based_cluster = cluster_mfccs(mfccs)\n\naccompanies_result = group_same_songs(\n    accompanies_based_cluster,\n    interval_threshold=10, duration_threshold=30\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:53:35.968496Z","iopub.execute_input":"2024-01-29T08:53:35.969176Z","iopub.status.idle":"2024-01-29T08:54:10.313219Z","shell.execute_reply.started":"2024-01-29T08:53:35.969140Z","shell.execute_reply":"2024-01-29T08:54:10.312246Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"264029f8323543adb682b1b639ff5b07"}},"metadata":{}}]},{"cell_type":"code","source":"higher_probability_timestamps = find_and_filter_overlapping_timestamps(accompanies_result, vocal_result)\nprint(higher_probability_timestamps.to_json())","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:54:10.314843Z","iopub.execute_input":"2024-01-29T08:54:10.315122Z","iopub.status.idle":"2024-01-29T08:54:10.329597Z","shell.execute_reply.started":"2024-01-29T08:54:10.315099Z","shell.execute_reply":"2024-01-29T08:54:10.328693Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"{\"start\":{\"0\":\"00:09:50\",\"1\":\"00:19:30\",\"2\":\"00:28:20\",\"3\":\"00:34:35\",\"4\":\"00:41:00\",\"5\":\"00:48:15\",\"6\":\"00:57:05\"},\"end\":{\"0\":\"00:14:20\",\"1\":\"00:24:40\",\"2\":\"00:32:55\",\"3\":\"00:38:55\",\"4\":\"00:46:05\",\"5\":\"00:53:15\",\"6\":\"00:59:45\"}}\n","output_type":"stream"}]},{"cell_type":"code","source":"def overlap(interval1, interval2):\n    return not (interval1['end'] < interval2['start'] or interval1['start'] > interval2['end'])\n\nnon_overlapping_rows = []\nfor index, row in vocal_result.iterrows():\n    interval = {'start': row['start'], 'end': row['end']}\n    overlaps = False\n    for _, hp_row in higher_probability_timestamps.iterrows():\n        hp_interval = {'start': hp_row['start'], 'end': hp_row['end']}\n        if overlap(interval, hp_interval):\n            overlaps = True\n            break\n    if not overlaps:\n        non_overlapping_rows.append(row)\n        \npossible_a_capella = pd.DataFrame(non_overlapping_rows).reset_index(drop=True)\n\nprint(possible_a_capella.to_json())","metadata":{"execution":{"iopub.status.busy":"2024-01-29T08:55:04.913867Z","iopub.execute_input":"2024-01-29T08:55:04.914662Z","iopub.status.idle":"2024-01-29T08:55:04.928297Z","shell.execute_reply.started":"2024-01-29T08:55:04.914630Z","shell.execute_reply":"2024-01-29T08:55:04.927154Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"{\"start\":{\"0\":\"01:07:45\"},\"end\":{\"0\":\"01:09:05\"}}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}