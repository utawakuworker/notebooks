{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7321687,"sourceType":"datasetVersion","datasetId":4249023},{"sourceId":7390759,"sourceType":"datasetVersion","datasetId":4296369}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install yt-dlp spleeter -q","metadata":{"_uuid":"874b103f-5550-4ad2-8d22-73e8e98eb196","_cell_guid":"a1625bc1-c21b-4496-b0d2-8f1fc3d19c74","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport re\nimport subprocess\nimport contextlib\nimport logging\nfrom functools import wraps\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport librosa\nimport yt_dlp\nfrom spleeter.separator import Separator\nimport ffmpeg\n\nimport torch\nimport torchaudio\nfrom transformers import AutoModelForAudioClassification, ASTFeatureExtractor","metadata":{"_uuid":"cbc7da9d-ed87-4781-acab-e0f064551462","_cell_guid":"79616bb2-fec4-4c9f-9aed-5d25b8f504ca","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T01:54:42.095799Z","iopub.execute_input":"2024-01-29T01:54:42.096106Z","iopub.status.idle":"2024-01-29T01:54:50.373382Z","shell.execute_reply.started":"2024-01-29T01:54:42.096078Z","shell.execute_reply":"2024-01-29T01:54:50.372618Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def suppress_output(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        # Redirect stdout and logging to os.devnull\n        with open(os.devnull, 'w') as fnull:\n            with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n                # Configure logging to use a NullHandler\n                null_handler = logging.NullHandler()\n                root_logger = logging.getLogger()\n                original_handlers = root_logger.handlers.copy()\n                root_logger.handlers = [null_handler]\n                try:\n                    result = func(*args, **kwargs)\n                finally:\n                    # Restore the original logging handlers\n                    root_logger.handlers = original_handlers\n        return result\n    return wrapper","metadata":{"_uuid":"885b28b5-a337-4fa9-bb41-b4fef004d71c","_cell_guid":"c0c99f87-bdf4-4466-b5c2-8373f5f03b71","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T01:54:50.374544Z","iopub.execute_input":"2024-01-29T01:54:50.375115Z","iopub.status.idle":"2024-01-29T01:54:50.381680Z","shell.execute_reply.started":"2024-01-29T01:54:50.375087Z","shell.execute_reply":"2024-01-29T01:54:50.380766Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#@suppress_output\ndef download_youtube_audio(url):\n    ydl_opts = {\n        'format': 'bestaudio',\n        'format_sort': ['+size'],\n        'outtmpl': '%(id)s.%(ext)s',\n        'postprocessors': [{\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': 'wav',  \n        }]\n    }\n\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n        ydl.download([url])\n        video_info = ydl.extract_info(url, download=False)\n    \n    video_path_local = Path(f\"{video_info['id']}.wav\")\n    \n    return video_path_local","metadata":{"_uuid":"ad6ff837-3a42-4bc1-a820-7eaf465c2a13","_cell_guid":"9492610c-5d60-4032-8a29-ad9730634f86","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T02:13:55.768686Z","iopub.execute_input":"2024-01-29T02:13:55.769080Z","iopub.status.idle":"2024-01-29T02:13:55.776675Z","shell.execute_reply.started":"2024-01-29T02:13:55.769037Z","shell.execute_reply":"2024-01-29T02:13:55.775647Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef slice_wav_by_length(input_file, outfile_name_pattern, desired_length=600):\n    # FFmpeg command to split the WAV file into 10-minute segments\n    command = [\n        'ffmpeg',\n        '-hide_banner',  # Added to hide FFmpeg banner\n        '-loglevel', 'error',  # Set log level to error\n        '-i', input_file,\n        '-f', 'segment',\n        '-segment_time', str(desired_length),\n        '-c', 'copy',\n        f\"{outfile_name_pattern}%03d.wav\"\n    ]\n\n    # Run the FFmpeg command\n    subprocess.run(command)","metadata":{"_uuid":"3bdcb9b9-b27e-4e95-9d82-24f66773eb52","_cell_guid":"5c95b893-79e4-43d8-932c-1552c2ff05e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T01:54:50.408474Z","iopub.execute_input":"2024-01-29T01:54:50.408728Z","iopub.status.idle":"2024-01-29T01:54:50.417636Z","shell.execute_reply.started":"2024-01-29T01:54:50.408707Z","shell.execute_reply":"2024-01-29T01:54:50.416901Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef seperate_vocal_and_accompanies(separator, output_paths):\n    output_directory = 'output'\n    os.makedirs(output_directory, exist_ok=True)\n    \n    for file_path in tqdm(output_paths, desc=\"Processing files\"):\n        output_file_path = os.path.join(output_directory, os.path.basename(file_path))\n        separator.separate_to_file(file_path, output_file_path)","metadata":{"_uuid":"a96c161d-9c80-4e16-93f5-ed24a729c206","_cell_guid":"f3660bd1-60de-4330-9e3f-baf6adf3de91","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T01:54:50.418805Z","iopub.execute_input":"2024-01-29T01:54:50.419103Z","iopub.status.idle":"2024-01-29T01:54:50.431856Z","shell.execute_reply.started":"2024-01-29T01:54:50.419080Z","shell.execute_reply":"2024-01-29T01:54:50.431110Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_filepaths_with_string_and_extension(\n    root_directory='.', target_string='', extension=''):\n    return sorted([os.path.abspath(os.path.join(root, file)) \n         for root, _, files in os.walk(root_directory)\n         for file in files \n         if target_string in file and (not extension or file.endswith(extension))]\n    )","metadata":{"_uuid":"59c4f791-3aec-43c1-b348-97b2425a6aa0","_cell_guid":"bfb39bec-3dff-4d7a-a766-2b5a443b0158","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-29T01:54:50.433012Z","iopub.execute_input":"2024-01-29T01:54:50.433320Z","iopub.status.idle":"2024-01-29T01:54:50.441387Z","shell.execute_reply.started":"2024-01-29T01:54:50.433291Z","shell.execute_reply":"2024-01-29T01:54:50.440657Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def load_and_slice_audio(vocal_paths, slice_duration=10):\n    all_samples = []\n    all_sampling_rates = []\n\n    for path in tqdm(vocal_paths):\n        waveform, sampling_rate = torchaudio.load(path)\n        waveform = waveform.squeeze().numpy()\n\n        num_slices = waveform.shape[-1] // (sampling_rate * slice_duration)\n\n        samples = [\n            torch.from_numpy(\n                waveform[:, i * sampling_rate * slice_duration : (i + 1) * sampling_rate * slice_duration]\n            )\n            for i in range(num_slices)\n        ]\n\n        all_samples.extend(samples)\n        all_sampling_rates.extend([sampling_rate] * num_slices)\n\n    return all_samples, all_sampling_rates","metadata":{"execution":{"iopub.status.busy":"2024-01-29T01:54:50.442440Z","iopub.execute_input":"2024-01-29T01:54:50.442697Z","iopub.status.idle":"2024-01-29T01:54:50.452842Z","shell.execute_reply.started":"2024-01-29T01:54:50.442675Z","shell.execute_reply":"2024-01-29T01:54:50.451991Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def get_common_sampling_rate(sampling_rates):\n    if len(set(sampling_rates)) == 1:\n        return int(sampling_rates[0])\n    else:\n        raise ValueError(\"All sampling rates should be the same.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-29T01:54:50.457279Z","iopub.execute_input":"2024-01-29T01:54:50.457527Z","iopub.status.idle":"2024-01-29T01:54:50.463382Z","shell.execute_reply.started":"2024-01-29T01:54:50.457506Z","shell.execute_reply":"2024-01-29T01:54:50.462538Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def predict_samples(model, feature_extractor, monofied_samples, sampling_rate, device):\n    result = []\n    raw_outputs = []\n\n    for i, sample in tqdm(enumerate(monofied_samples), total=len(monofied_samples), desc=\"Processing samples\"):\n        inputs = feature_extractor(\n            sample, feature_size=2, sampling_rate=sampling_rate, \n            padding=\"max_length\", return_tensors=\"pt\"\n        )\n        \n        input_values = inputs.input_values.to(device)\n\n        with torch.no_grad():\n            outputs = model(input_values)\n            predicted_labels = model.config.id2label[outputs.logits.argmax(-1).item()]\n            result.append([i, predicted_labels])\n            raw_outputs.append(outputs)\n\n    return result, raw_outputs","metadata":{"execution":{"iopub.status.busy":"2024-01-29T01:54:50.464441Z","iopub.execute_input":"2024-01-29T01:54:50.464674Z","iopub.status.idle":"2024-01-29T01:54:50.477626Z","shell.execute_reply.started":"2024-01-29T01:54:50.464654Z","shell.execute_reply":"2024-01-29T01:54:50.476824Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def create_dataframe(predictions, time_window_length):\n    df = pd.DataFrame(predictions, columns=['index', 'class'])\n    df['start'] = df['index'].apply(lambda x: seconds_to_hhmmss(x*time_window_length))\n    df['end'] = df['index'].apply(lambda x: seconds_to_hhmmss((x+1)*time_window_length))\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-01-29T03:34:44.039932Z","iopub.execute_input":"2024-01-29T03:34:44.040705Z","iopub.status.idle":"2024-01-29T03:34:44.046090Z","shell.execute_reply.started":"2024-01-29T03:34:44.040674Z","shell.execute_reply":"2024-01-29T03:34:44.045038Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"def audio_analyzer(file_paths, model, device, slice_duration):\n    sliced_samples, sampling_rates = load_and_slice_audio(file_paths, slice_duration)\n    monofied_samples = [torch.mean(x, dim=0) for x in sliced_samples]\n    sampling_rate = get_common_sampling_rate(sampling_rates)\n\n    feature_extractor = ASTFeatureExtractor(\n        sampling_rate=sampling_rate, do_normalize=True\n    )\n\n    predictions, raw_outputs = predict_samples(\n        model, feature_extractor, monofied_samples, sampling_rate, device\n    )\n\n    result_df = create_dataframe(predictions, time_window_length=slice_duration)\n\n    return result_df, raw_outputs","metadata":{"execution":{"iopub.status.busy":"2024-01-29T01:54:50.488007Z","iopub.execute_input":"2024-01-29T01:54:50.488269Z","iopub.status.idle":"2024-01-29T01:54:50.497079Z","shell.execute_reply.started":"2024-01-29T01:54:50.488247Z","shell.execute_reply":"2024-01-29T01:54:50.496215Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def class_manipulator_old(input_df):\n    # Create a copy of the input DataFrame to avoid modifying the original\n    df = input_df.copy()\n\n    # Binarize the 'class' column\n    df['binarized_class'] = df['class'].apply(\n        lambda x: 0 if (x in ['Speech','Tick', 'Clicking', ]) else 1\n    )\n\n    # Create the 'group' column\n    df['group'] = (df['binarized_class'] != df['binarized_class'].shift()).cumsum()\n\n    # Group the DataFrame by the new 'group' column\n    grouped_df = df.groupby(['binarized_class', 'group']).agg(\n        start=('start', 'first'),\n        end=('end', 'last'),\n        class_value=('class', 'first')\n    ).reset_index(drop=True)\n\n    # Filter out unwanted classes and sort by 'start'\n    intermediate_df = grouped_df[\n        ~grouped_df['class_value'].isin(['Speech','Tick', 'Clicking',])\n    ].sort_values('start').reset_index(drop=True)\n\n    return intermediate_df","metadata":{"execution":{"iopub.status.busy":"2024-01-29T01:54:50.498404Z","iopub.execute_input":"2024-01-29T01:54:50.498725Z","iopub.status.idle":"2024-01-29T01:54:50.508155Z","shell.execute_reply.started":"2024-01-29T01:54:50.498695Z","shell.execute_reply":"2024-01-29T01:54:50.507339Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def class_manipulator(input_df, singing_like_classes):\n    \n    def _get_most_frequent_with_fallback(x):\n        modes = x.mode()\n        if not modes.empty:\n            if any(mode in singing_like_classes for mode in modes):\n                return 'Singing'\n        return None #'Speech'\n    \n    # Create a copy of the input DataFrame to avoid modifying the original\n    df = input_df.copy()\n    \n    # Binarize the 'class' column\n    df['binarized_class'] = df['class'].apply(\n        lambda x : 1 if (x in singing_like_classes) else 0\n    )\n\n    # Create the 'group' column\n    df['group'] = (df['binarized_class'] != df['binarized_class'].shift()).cumsum()\n\n    # Group the DataFrame by the new 'group' column\n    grouped_df = df.groupby(['binarized_class', 'group']).agg(\n        start=('start', 'first'),\n        end=('end', 'last'),\n        class_value=('class', _get_most_frequent_with_fallback) \n    ).reset_index(drop=True).dropna()\n\n    return grouped_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T01:54:50.509177Z","iopub.execute_input":"2024-01-29T01:54:50.509428Z","iopub.status.idle":"2024-01-29T01:54:50.522503Z","shell.execute_reply.started":"2024-01-29T01:54:50.509400Z","shell.execute_reply":"2024-01-29T01:54:50.521691Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def group_same_songs(input_df, interval_threshold, duration_threshold):\n    \n    df = input_df.copy()\n\n    df['start'] = pd.to_datetime(df['start'])\n    df['end'] = pd.to_datetime(df['end'])\n\n    df['group'] = 0\n\n    for i in range(1, len(df)):\n        if (df['start'][i] - df['end'][i - 1]).total_seconds() <= interval_threshold:\n            df.at[i, 'group'] = df.at[i - 1, 'group']\n        else:\n            df.at[i, 'group'] = df.at[i - 1, 'group'] + 1\n\n    grouped_df = df.groupby('group')\n\n    for group, group_df in grouped_df:\n        duration = (group_df['end'].max() - group_df['start'].min()).total_seconds()\n        if duration < duration_threshold:\n            df = df[df['group'] != group]\n\n    df = df.drop(columns=['class_value'])\n\n    df = df.groupby('group').agg({'start':'first', 'end':'last'})\n\n    df['start'] = df['start'].apply(lambda x:x.strftime('%H:%M:%S'))\n    df['end'] = df['end'].apply(lambda x:x.strftime('%H:%M:%S'))\n    \n    return df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T02:34:33.583425Z","iopub.execute_input":"2024-01-29T02:34:33.584074Z","iopub.status.idle":"2024-01-29T02:34:33.594991Z","shell.execute_reply.started":"2024-01-29T02:34:33.584042Z","shell.execute_reply":"2024-01-29T02:34:33.593546Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def mfcc_from_accompanies(accompanies_paths, slice_duration=5):\n\n    sliced_samples, sampling_rates = load_and_slice_audio(accompanies_paths, slice_duration)\n    monofied_samples = [torch.mean(x, dim=0) for x in sliced_samples]\n    sampling_rate = get_common_sampling_rate(sampling_rates)\n    mfccs = [librosa.feature.mfcc(y=y.numpy(), sr=sampling_rate, n_mfcc=13) \n             for y in monofied_samples]\n    \n    return mfccs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cluster_mfccs(mfccs):\n    full_flattens = [x.flatten() for x in mfccs]\n    kmeans = KMeans(n_clusters=2, n_init=2)  # You can choose the number of clusters\n    kmeans.fit(full_flattens)\n    cluster_labels = kmeans.labels_\n\n    indices = np.arange(len(cluster_labels))\n    temp_df = create_dataframe(np.vstack((indices, cluster_labels)).T, time_window_length=5)\n\n    value_counts = temp_df['class'].value_counts()\n    major_value = value_counts.idxmax()\n    minor_value = value_counts.idxmin()\n\n    label_mapping = {major_value: 'Speech', minor_value: 'Singing'}\n    temp_df['class_value'] = temp_df['class'].map(label_mapping)\n\n    return temp_df[temp_df['class_value']=='Singing'].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T03:43:41.562160Z","iopub.execute_input":"2024-01-29T03:43:41.563167Z","iopub.status.idle":"2024-01-29T03:43:41.572115Z","shell.execute_reply.started":"2024-01-29T03:43:41.563114Z","shell.execute_reply":"2024-01-29T03:43:41.571038Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"def seconds_to_hhmmss(total_seconds):\n    m, s = divmod(total_seconds, 60)\n    h, m = divmod(m, 60)\n    return f\"{h:02d}:{m:02d}:{s:02d}\"\n        \ndef hhmmss_to_seconds(hms):\n    h, m, s = map(int, hms.split(':'))\n    return h * 3600 + m * 60 + s","metadata":{"execution":{"iopub.status.busy":"2024-01-29T03:40:22.936816Z","iopub.execute_input":"2024-01-29T03:40:22.937457Z","iopub.status.idle":"2024-01-29T03:40:22.943076Z","shell.execute_reply.started":"2024-01-29T03:40:22.937425Z","shell.execute_reply":"2024-01-29T03:40:22.941956Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"code","source":"def check_overlap(interval1_start, interval1_end, interval2_start, interval2_end):\n    return (interval1_start <= interval2_end and interval1_end >= interval2_start) or \\\n           (interval2_start <= interval1_end and interval2_end >= interval1_start)\n\ndef find_and_filter_overlapping_timestamps(accompanies_df, vocal_df):\n    unique_overlapping_timestamps = []\n\n    for _, row1 in accompanies_df.iterrows():\n        for _, row2 in vocal_df.iterrows():\n            start1_seconds = hhmmss_to_seconds(row1['start'])\n            end1_seconds = hhmmss_to_seconds(row1['end'])\n            start2_seconds = hhmmss_to_seconds(row2['start'])\n            end2_seconds = hhmmss_to_seconds(row2['end'])\n\n            # Check for overlap\n            if check_overlap(start1_seconds, end1_seconds, start2_seconds, end2_seconds):\n                overlap_start = min(start1_seconds, start2_seconds)\n                overlap_end = max(end1_seconds, end2_seconds)\n                overlapping_timestamp = {\n                    'start': seconds_to_hhmmss(overlap_start),\n                    'end': seconds_to_hhmmss(overlap_end)\n                }\n                if overlapping_timestamp not in unique_overlapping_timestamps:\n                    unique_overlapping_timestamps.append(overlapping_timestamp)\n\n    # Filter out redundant overlaps\n    filtered_overlapping_timestamps = [\n        overlap for overlap in unique_overlapping_timestamps\n        if all(\n            not (\n                hhmmss_to_seconds(overlap['start']) >= hhmmss_to_seconds(other_overlap['start']) and\n                hhmmss_to_seconds(overlap['end']) <= hhmmss_to_seconds(other_overlap['end'])\n            )\n            for other_overlap in unique_overlapping_timestamps\n            if overlap != other_overlap\n        )\n    ]\n\n    merged_result = pd.DataFrame(filtered_overlapping_timestamps)\n\n    return merged_result","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf ./output\n\noutput_filename_pattern = 'noa'\nroot_dir = '.'  \nyoutube_url = 'https://www.youtube.com/watch?v=uvuDBBDUnEs'\n\nseparator = Separator(\"spleeter:2stems\")\n\nslice_wav_by_length(download_youtube_audio(youtube_url), output_filename_pattern)\n\nwav_slice_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = output_filename_pattern, extension='wav'\n)\n\nseperate_vocal_and_accompanies(separator, wav_slice_paths)\n\naccompanies_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'accompaniment', extension='wav'\n)\n\nvocal_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'vocal', extension='wav'\n)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel = AutoModelForAudioClassification.from_pretrained(\n    \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n).to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_vocal, raw_outputs = audio_analyzer(\n    vocal_paths, model, device, slice_duration=5\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T02:25:16.515661Z","iopub.execute_input":"2024-01-29T02:25:16.516577Z","iopub.status.idle":"2024-01-29T02:26:17.200802Z","shell.execute_reply.started":"2024-01-29T02:25:16.516527Z","shell.execute_reply":"2024-01-29T02:26:17.200035Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5421c46895c645b4989300471538d030"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing samples:   0%|          | 0/840 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdcc0b8b0ce749c689d167d8595fe3a8"}},"metadata":{}}]},{"cell_type":"code","source":"classes = model.config.id2label\nsinging_like_indices = [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 112, 113, 114, 116, 117, 118, 119, 120, 136, 254, 255, 266, 259, 268, 269, 271, 402, 496, 503,523, 526]\nsinging_like_classes = [classes.get(x) for x in singing_like_indices]","metadata":{"execution":{"iopub.status.busy":"2024-01-29T02:27:23.780342Z","iopub.execute_input":"2024-01-29T02:27:23.781207Z","iopub.status.idle":"2024-01-29T02:27:23.786801Z","shell.execute_reply.started":"2024-01-29T02:27:23.781176Z","shell.execute_reply":"2024-01-29T02:27:23.785829Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"vocal_result = group_same_songs(\n    class_manipulator(result_vocal, singing_like_classes),\n    interval_threshold=10, duration_threshold=30\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T04:31:11.233719Z","iopub.execute_input":"2024-01-29T04:31:11.234583Z","iopub.status.idle":"2024-01-29T04:31:11.289270Z","shell.execute_reply.started":"2024-01-29T04:31:11.234538Z","shell.execute_reply":"2024-01-29T04:31:11.288328Z"},"trusted":true},"execution_count":296,"outputs":[]},{"cell_type":"code","source":"mfccs = mfcc_from_accompanies(accompanies_paths, slice_duration=5)\naccompanies_based_cluster = cluster_mfccs(mfccs)\n\naccompanies_result = group_same_songs(\n    accompanies_based_cluster,\n    interval_threshold=10, duration_threshold=30\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-29T04:12:36.158481Z","iopub.execute_input":"2024-01-29T04:12:36.158817Z","iopub.status.idle":"2024-01-29T04:12:55.220516Z","shell.execute_reply.started":"2024-01-29T04:12:36.158791Z","shell.execute_reply":"2024-01-29T04:12:55.219403Z"},"trusted":true},"execution_count":254,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25c137cc758d42b2abb97010f6ed8f36"}},"metadata":{}}]},{"cell_type":"code","source":"higher_probability_timestamps = find_and_filter_overlapping_timestamps(accompanies_result, vocal_result)\nprint(higher_probability_timestamps.to_json())","metadata":{"execution":{"iopub.status.busy":"2024-01-29T04:39:46.797405Z","iopub.execute_input":"2024-01-29T04:39:46.798177Z","iopub.status.idle":"2024-01-29T04:39:46.814541Z","shell.execute_reply.started":"2024-01-29T04:39:46.798143Z","shell.execute_reply":"2024-01-29T04:39:46.813451Z"},"trusted":true},"execution_count":310,"outputs":[{"name":"stdout","text":"      start       end\n0  00:09:50  00:14:20\n1  00:19:30  00:24:40\n2  00:28:20  00:32:55\n3  00:34:35  00:38:55\n4  00:41:00  00:46:05\n5  00:48:15  00:53:15\n6  00:57:05  00:59:45\n","output_type":"stream"}]},{"cell_type":"code","source":"non_overlapping_rows = []\nfor index, row in vocal_result.iterrows():\n    interval = {'start': row['start'], 'end': row['end']}\n    overlaps = False\n    for _, hp_row in higher_probability_timestamps.iterrows():\n        hp_interval = {'start': hp_row['start'], 'end': hp_row['end']}\n        if overlap(interval, hp_interval):\n            overlaps = True\n            break\n    if not overlaps:\n        non_overlapping_rows.append(row)\n        \npossible_a_capella = pd.DataFrame(non_overlapping_rows).reset_index(drop=True)\n\nprint(possible_a_capella.to_json())","metadata":{"execution":{"iopub.status.busy":"2024-01-29T04:52:36.408311Z","iopub.execute_input":"2024-01-29T04:52:36.409312Z","iopub.status.idle":"2024-01-29T04:52:36.426491Z","shell.execute_reply.started":"2024-01-29T04:52:36.409266Z","shell.execute_reply":"2024-01-29T04:52:36.425286Z"},"trusted":true},"execution_count":312,"outputs":[{"name":"stdout","text":"{\"start\":{\"0\":\"01:07:45\"},\"end\":{\"0\":\"01:09:05\"}}\n","output_type":"stream"}]}]}