{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7321687,"sourceType":"datasetVersion","datasetId":4249023},{"sourceId":7390759,"sourceType":"datasetVersion","datasetId":4296369}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install yt-dlp spleeter -q","metadata":{"_uuid":"874b103f-5550-4ad2-8d22-73e8e98eb196","_cell_guid":"a1625bc1-c21b-4496-b0d2-8f1fc3d19c74","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:57:20.783402Z","iopub.execute_input":"2024-01-14T06:57:20.784435Z","iopub.status.idle":"2024-01-14T06:58:49.306965Z","shell.execute_reply.started":"2024-01-14T06:57:20.784393Z","shell.execute_reply":"2024-01-14T06:58:49.305758Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.12.1 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.19.6 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask 2023.12.0 requires click>=8.1, but you have click 7.1.2 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndistributed 2023.12.0 requires click>=8.0, but you have click 7.1.2 which is incompatible.\nfiona 1.9.5 requires click~=8.0, but you have click 7.1.2 which is incompatible.\nfitter 1.6.0 requires click<9.0.0,>=8.1.6, but you have click 7.1.2 which is incompatible.\nfitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 1.5.3 which is incompatible.\nflask 3.0.0 requires click>=8.1.3, but you have click 7.1.2 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.12.2 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-pubsub 2.18.3 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\nkfp 2.0.1 requires click<9,>=8.0.0, but you have click 7.1.2 which is incompatible.\nkfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nonnx 1.15.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.5.0 requires tensorflow~=2.13.0, but you have tensorflow 2.9.3 which is incompatible.\ntensorflow-serving-api 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.13.0 requires tensorflow<3,>=2.13.0, but you have tensorflow 2.9.3 which is incompatible.\ntensorflow-text 2.13.0 requires tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.9.3 which is incompatible.\ntensorflowjs 4.14.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\ntensorflowjs 4.14.0 requires tensorflow<3,>=2.13.0, but you have tensorflow 2.9.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport re\nimport subprocess\nimport contextlib\nimport logging\nfrom functools import wraps\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport librosa\nimport yt_dlp\nfrom spleeter.separator import Separator\nimport ffmpeg\n\nimport torch\nimport torchaudio\nfrom transformers import AutoModelForAudioClassification, ASTFeatureExtractor","metadata":{"_uuid":"cbc7da9d-ed87-4781-acab-e0f064551462","_cell_guid":"79616bb2-fec4-4c9f-9aed-5d25b8f504ca","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:49.309144Z","iopub.execute_input":"2024-01-14T06:58:49.309891Z","iopub.status.idle":"2024-01-14T06:58:54.631615Z","shell.execute_reply.started":"2024-01-14T06:58:49.309860Z","shell.execute_reply":"2024-01-14T06:58:54.630827Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def suppress_output(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        # Redirect stdout and logging to os.devnull\n        with open(os.devnull, 'w') as fnull:\n            with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n                # Configure logging to use a NullHandler\n                null_handler = logging.NullHandler()\n                root_logger = logging.getLogger()\n                original_handlers = root_logger.handlers.copy()\n                root_logger.handlers = [null_handler]\n                try:\n                    result = func(*args, **kwargs)\n                finally:\n                    # Restore the original logging handlers\n                    root_logger.handlers = original_handlers\n        return result\n    return wrapper","metadata":{"_uuid":"885b28b5-a337-4fa9-bb41-b4fef004d71c","_cell_guid":"c0c99f87-bdf4-4466-b5c2-8373f5f03b71","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.632751Z","iopub.execute_input":"2024-01-14T06:58:54.633285Z","iopub.status.idle":"2024-01-14T06:58:54.640060Z","shell.execute_reply.started":"2024-01-14T06:58:54.633258Z","shell.execute_reply":"2024-01-14T06:58:54.639213Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def seconds_to_hh_mm_ss(total_seconds):\n    hours = total_seconds // 3600\n    minutes = (total_seconds % 3600) // 60\n    seconds = total_seconds % 60\n    return f\"{hours:02}:{minutes:02}:{seconds:02}\"","metadata":{"_uuid":"12e3b558-121c-4cb0-95f3-5591dafc6f70","_cell_guid":"b38e8abc-bc2a-40ba-8e41-905f94d0b561","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.643240Z","iopub.execute_input":"2024-01-14T06:58:54.643810Z","iopub.status.idle":"2024-01-14T06:58:54.654046Z","shell.execute_reply.started":"2024-01-14T06:58:54.643776Z","shell.execute_reply":"2024-01-14T06:58:54.653283Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef download_youtube_audio(url):\n    ydl_opts = {\n        'format': 'bestaudio',\n        'format_sort': ['+size'],\n        'outtmpl': '%(id)s.%(ext)s',\n        'postprocessors': [{\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': 'wav',  \n        }]\n    }\n\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n        ydl.download([url])\n        video_info = ydl.extract_info(url, download=False)\n    \n    video_path_local = Path(f\"{video_info['id']}.wav\")\n    \n    return video_path_local","metadata":{"_uuid":"ad6ff837-3a42-4bc1-a820-7eaf465c2a13","_cell_guid":"9492610c-5d60-4032-8a29-ad9730634f86","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.655180Z","iopub.execute_input":"2024-01-14T06:58:54.655764Z","iopub.status.idle":"2024-01-14T06:58:54.664599Z","shell.execute_reply.started":"2024-01-14T06:58:54.655730Z","shell.execute_reply":"2024-01-14T06:58:54.663778Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef slice_wav_by_length(input_file, outfile_name_pattern, desired_length=600):\n    # FFmpeg command to split the WAV file into 10-minute segments\n    command = [\n        'ffmpeg',\n        '-hide_banner',  # Added to hide FFmpeg banner\n        '-loglevel', 'error',  # Set log level to error\n        '-i', input_file,\n        '-f', 'segment',\n        '-segment_time', str(desired_length),\n        '-c', 'copy',\n        f\"{outfile_name_pattern}%03d.wav\"\n    ]\n\n    # Run the FFmpeg command\n    subprocess.run(command)","metadata":{"_uuid":"3bdcb9b9-b27e-4e95-9d82-24f66773eb52","_cell_guid":"5c95b893-79e4-43d8-932c-1552c2ff05e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.665641Z","iopub.execute_input":"2024-01-14T06:58:54.665930Z","iopub.status.idle":"2024-01-14T06:58:54.677347Z","shell.execute_reply.started":"2024-01-14T06:58:54.665906Z","shell.execute_reply":"2024-01-14T06:58:54.676622Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef seperate_vocal_and_accompanies(separator, output_paths):\n    output_directory = 'output'\n    os.makedirs(output_directory, exist_ok=True)\n    \n    for file_path in tqdm(output_paths, desc=\"Processing files\"):\n        output_file_path = os.path.join(output_directory, os.path.basename(file_path))\n        separator.separate_to_file(file_path, output_file_path)","metadata":{"_uuid":"a96c161d-9c80-4e16-93f5-ed24a729c206","_cell_guid":"f3660bd1-60de-4330-9e3f-baf6adf3de91","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.678150Z","iopub.execute_input":"2024-01-14T06:58:54.678405Z","iopub.status.idle":"2024-01-14T06:58:54.688230Z","shell.execute_reply.started":"2024-01-14T06:58:54.678383Z","shell.execute_reply":"2024-01-14T06:58:54.687478Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_filepaths_with_string_and_extension(\n    root_directory='.', target_string='', extension=''):\n    return sorted([os.path.abspath(os.path.join(root, file)) \n         for root, _, files in os.walk(root_directory)\n         for file in files \n         if target_string in file and (not extension or file.endswith(extension))]\n    )","metadata":{"_uuid":"59c4f791-3aec-43c1-b348-97b2425a6aa0","_cell_guid":"bfb39bec-3dff-4d7a-a766-2b5a443b0158","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.689359Z","iopub.execute_input":"2024-01-14T06:58:54.689670Z","iopub.status.idle":"2024-01-14T06:58:54.697753Z","shell.execute_reply.started":"2024-01-14T06:58:54.689645Z","shell.execute_reply":"2024-01-14T06:58:54.696956Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def extract_mfccs(file_paths, n_mfcc):\n    mfccs = []\n\n    for file_path in tqdm(file_paths, desc=\"Extracting MFCCs\"):\n        # Load audio file\n        y, sr = librosa.load(file_path)\n\n        # Extract MFCCs\n        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n        \n        # Append to the list\n        mfccs.append(mfcc)\n\n    return np.hstack(mfccs)","metadata":{"_uuid":"89df5311-4f21-4e54-90d1-61600e56c076","_cell_guid":"cffa9301-8132-4110-8f42-c7e288e2dc3e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.698852Z","iopub.execute_input":"2024-01-14T06:58:54.699160Z","iopub.status.idle":"2024-01-14T06:58:54.708001Z","shell.execute_reply.started":"2024-01-14T06:58:54.699124Z","shell.execute_reply":"2024-01-14T06:58:54.707223Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def slice_mfccs_by_length(mfccs, segment_length=256):\n    # Calculate the number of splits such that all arrays have the same length\n    num_splits = mfccs.shape[-1] // segment_length\n    # Calculate the new shape length\n    new_shape_length = num_splits * segment_length\n    # Split the array and discard any remainder\n    split_arrays = np.array_split(mfccs[:, :new_shape_length], num_splits, axis=1)\n    return split_arrays","metadata":{"_uuid":"e763257f-9405-4594-bef3-50c798bca709","_cell_guid":"9bd437c3-7a37-459e-b7a9-826362e9e4ea","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.711671Z","iopub.execute_input":"2024-01-14T06:58:54.711927Z","iopub.status.idle":"2024-01-14T06:58:54.721227Z","shell.execute_reply.started":"2024-01-14T06:58:54.711905Z","shell.execute_reply":"2024-01-14T06:58:54.720429Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def load_and_slice_audio(vocal_paths, slice_duration=10):\n    all_samples = []\n    all_sampling_rates = []\n\n    for path in tqdm(vocal_paths):\n        waveform, sampling_rate = torchaudio.load(path)\n        waveform = waveform.squeeze().numpy()\n\n        num_slices = waveform.shape[-1] // (sampling_rate * slice_duration)\n\n        samples = [\n            torch.from_numpy(\n                waveform[:, i * sampling_rate * slice_duration : (i + 1) * sampling_rate * slice_duration]\n            )\n            for i in range(num_slices)\n        ]\n\n        all_samples.extend(samples)\n        all_sampling_rates.extend([sampling_rate] * num_slices)\n\n    return all_samples, all_sampling_rates","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.700845Z","iopub.execute_input":"2024-01-14T06:58:58.701384Z","iopub.status.idle":"2024-01-14T06:58:58.708135Z","shell.execute_reply.started":"2024-01-14T06:58:58.701358Z","shell.execute_reply":"2024-01-14T06:58:58.707192Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_common_sampling_rate(sampling_rates):\n    if len(set(sampling_rates)) == 1:\n        return int(sampling_rates[0])\n    else:\n        raise ValueError(\"All sampling rates should be the same.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.709425Z","iopub.execute_input":"2024-01-14T06:58:58.710110Z","iopub.status.idle":"2024-01-14T06:58:58.718797Z","shell.execute_reply.started":"2024-01-14T06:58:58.710076Z","shell.execute_reply":"2024-01-14T06:58:58.717879Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def predict_samples(model, feature_extractor, monofied_samples, sampling_rate, device):\n    result = []\n\n    for i, sample in tqdm(enumerate(monofied_samples), total=len(monofied_samples), desc=\"Processing samples\"):\n        inputs = feature_extractor(\n            sample, sampling_rate=sampling_rate, \n            padding=\"max_length\", return_tensors=\"pt\"\n        )\n        \n        input_values = inputs.input_values.to(device)\n\n        with torch.no_grad():\n            outputs = model(input_values)\n            predicted_labels = model.config.id2label[outputs.logits.argmax(-1).item()]\n            result.append([i, predicted_labels])\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.720057Z","iopub.execute_input":"2024-01-14T06:58:58.720613Z","iopub.status.idle":"2024-01-14T06:58:58.730512Z","shell.execute_reply.started":"2024-01-14T06:58:58.720569Z","shell.execute_reply":"2024-01-14T06:58:58.729617Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def create_dataframe(predictions):\n    df = pd.DataFrame(predictions, columns=['index', 'class'])\n    df['start'] = df['index'].apply(lambda x: seconds_to_hh_mm_ss(x*10))\n    df['end'] = df['index'].apply(lambda x: seconds_to_hh_mm_ss((x+1)*10))\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.731554Z","iopub.execute_input":"2024-01-14T06:58:58.731949Z","iopub.status.idle":"2024-01-14T06:58:58.743671Z","shell.execute_reply.started":"2024-01-14T06:58:58.731901Z","shell.execute_reply":"2024-01-14T06:58:58.742889Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def audio_analyzer(file_paths, model, device):\n    sliced_samples, sampling_rates = load_and_slice_audio(file_paths)\n    monofied_samples = [torch.mean(x, dim=0) for x in sliced_samples]\n    sampling_rate = get_common_sampling_rate(sampling_rates)\n\n    feature_extractor = ASTFeatureExtractor(sampling_rate=sampling_rate)\n\n    predictions = predict_samples(\n        model, feature_extractor, monofied_samples, sampling_rate, device\n    )\n\n    result_df = create_dataframe(predictions)\n\n    return result_df","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.744601Z","iopub.execute_input":"2024-01-14T06:58:58.744883Z","iopub.status.idle":"2024-01-14T06:58:58.752810Z","shell.execute_reply.started":"2024-01-14T06:58:58.744859Z","shell.execute_reply":"2024-01-14T06:58:58.752075Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def class_manipulator(input_df):\n    # Create a copy of the input DataFrame to avoid modifying the original\n    df = input_df.copy()\n\n    # Binarize the 'class' column\n    df['binarized_class'] = df['class'].apply(\n        lambda x: 0 if (x in ['Speech', 'Music', 'Tick', 'Clicking', 'Silence', 'Whistling']) else 1\n    )\n\n    # Create the 'group' column\n    df['group'] = (df['binarized_class'] != df['binarized_class'].shift()).cumsum()\n\n    # Group the DataFrame by the new 'group' column\n    grouped_df = df.groupby(['binarized_class', 'group']).agg(\n        start=('start', 'first'),\n        end=('end', 'last'),\n        class_value=('class', 'first')\n    ).reset_index(drop=True)\n\n    # Filter out unwanted classes and sort by 'start'\n    intermediate_df = grouped_df[\n        ~grouped_df['class_value'].isin(['Speech', 'Music', 'Tick', 'Clicking', 'Silence'])\n    ].sort_values('start').reset_index(drop=True)\n\n    return intermediate_df","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.753946Z","iopub.execute_input":"2024-01-14T06:58:58.754204Z","iopub.status.idle":"2024-01-14T06:58:58.763001Z","shell.execute_reply.started":"2024-01-14T06:58:58.754181Z","shell.execute_reply":"2024-01-14T06:58:58.762222Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def group_same_songs(input_df, interval_threshold, duration_threshold):\n    \n    df = input_df.copy()\n\n    # Convert 'start' and 'end' columns to datetime\n    df['start'] = pd.to_datetime(df['start'])\n    df['end'] = pd.to_datetime(df['end'])\n\n    # Create a new column 'group' and initialize with 0\n    df['group'] = 0\n\n    # Iterate through rows and update the 'group' column based on the specified threshold\n    for i in range(1, len(df)):\n        if (df['start'][i] - df['end'][i - 1]).total_seconds() <= interval_threshold:\n            df.at[i, 'group'] = df.at[i - 1, 'group']\n        else:\n            df.at[i, 'group'] = df.at[i - 1, 'group'] + 1\n\n    # Group by 'group' column\n    grouped_df = df.groupby('group')\n\n    # Iterate through groups and drop if the total duration is less than 30 seconds\n    for group, group_df in grouped_df:\n        duration = (group_df['end'].max() - group_df['start'].min()).total_seconds()\n        if duration < duration_threshold:\n            df = df[df['group'] != group]\n\n    # Drop the 'class_value' column\n    df = df.drop(columns=['class_value'])\n\n    # Reset the index after dropping rows\n    df = df.reset_index(drop=True)\n\n    # Group by 'group' column and aggregate 'start' and 'end' columns\n    df = df.groupby('group').agg({'start':'first', 'end':'last'})\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.764060Z","iopub.execute_input":"2024-01-14T06:58:58.764321Z","iopub.status.idle":"2024-01-14T06:58:58.777035Z","shell.execute_reply.started":"2024-01-14T06:58:58.764291Z","shell.execute_reply":"2024-01-14T06:58:58.776226Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"output_filename_pattern = 'slice_'\nroot_dir = '.'  \nyoutube_url = 'https://www.youtube.com/watch?v=AWbCwBgkJfQ'\n\nseparator = Separator(\"spleeter:2stems\")\n\nslice_wav_by_length(download_youtube_audio(youtube_url), output_filename_pattern)\n\nwav_slice_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = output_filename_pattern, extension='wav'\n)\n\nseperate_vocal_and_accompanies(separator, wav_slice_paths)\n\naccompanies_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'accompaniment', extension='wav'\n)\n\nvocal_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'vocal', extension='wav'\n)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel = AutoModelForAudioClassification.from_pretrained(\n    \"MIT/ast-finetuned-audioset-10-10-0.4593\").to(device)\n\nresult_vocal = audio_analyzer(vocal_paths, model, device)\ngroup_same_songs(class_manipulator(result_vocal), \n                 interval_threshold=30, duration_threshold=20)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.778283Z","iopub.execute_input":"2024-01-14T06:58:58.778795Z","iopub.status.idle":"2024-01-14T07:00:50.329976Z","shell.execute_reply.started":"2024-01-14T06:58:58.778763Z","shell.execute_reply":"2024-01-14T07:00:50.328817Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f953a041b99c43b4b958a53017d9b875"}},"metadata":{}},{"name":"stdout","text":"INFO:spleeter:File output/slice_000.wav/slice_000/vocals.wav written succesfully\nINFO:spleeter:File output/slice_000.wav/slice_000/accompaniment.wav written succesfully\nINFO:spleeter:File output/slice_001.wav/slice_001/vocals.wav written succesfully\nINFO:spleeter:File output/slice_001.wav/slice_001/accompaniment.wav written succesfully\nINFO:spleeter:File output/slice_002.wav/slice_002/vocals.wav written succesfully\nINFO:spleeter:File output/slice_002.wav/slice_002/accompaniment.wav written succesfully\nINFO:spleeter:File output/slice_003.wav/slice_003/vocals.wav written succesfully\nINFO:spleeter:File output/slice_003.wav/slice_003/accompaniment.wav written succesfully\nINFO:spleeter:File output/slice_004.wav/slice_004/vocals.wav written succesfully\nINFO:spleeter:File output/slice_004.wav/slice_004/accompaniment.wav written succesfully\nINFO:spleeter:File output/slice_005.wav/slice_005/vocals.wav written succesfully\nINFO:spleeter:File output/slice_005.wav/slice_005/accompaniment.wav written succesfully\nINFO:spleeter:File output/slice_006.wav/slice_006/vocals.wav written succesfully\nINFO:spleeter:File output/slice_006.wav/slice_006/accompaniment.wav written succesfully\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"914ac9deeb664f85b7232dfa96e13b35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc5b0c6c2cea47499cabbdb2703ff565"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5010572790194957b6122311f2bdc14d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing samples:   0%|          | 0/369 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c19ca1894c443a883f328f34ef17687"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"                    start                 end\ngroup                                        \n0     2024-01-14 00:00:10 2024-01-14 00:02:20\n1     2024-01-14 00:06:20 2024-01-14 00:10:30\n4     2024-01-14 00:16:20 2024-01-14 00:17:00\n5     2024-01-14 00:17:50 2024-01-14 00:18:10\n6     2024-01-14 00:18:50 2024-01-14 00:19:50\n7     2024-01-14 00:25:20 2024-01-14 00:29:40\n8     2024-01-14 00:34:10 2024-01-14 00:38:10\n10    2024-01-14 00:41:40 2024-01-14 00:42:00\n11    2024-01-14 00:42:50 2024-01-14 00:44:30\n12    2024-01-14 00:47:30 2024-01-14 00:51:30\n13    2024-01-14 00:54:40 2024-01-14 00:57:30\n15    2024-01-14 01:00:50 2024-01-14 01:01:10","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n    <tr>\n      <th>group</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-01-14 00:00:10</td>\n      <td>2024-01-14 00:02:20</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-01-14 00:06:20</td>\n      <td>2024-01-14 00:10:30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-01-14 00:16:20</td>\n      <td>2024-01-14 00:17:00</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2024-01-14 00:17:50</td>\n      <td>2024-01-14 00:18:10</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2024-01-14 00:18:50</td>\n      <td>2024-01-14 00:19:50</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2024-01-14 00:25:20</td>\n      <td>2024-01-14 00:29:40</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2024-01-14 00:34:10</td>\n      <td>2024-01-14 00:38:10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2024-01-14 00:41:40</td>\n      <td>2024-01-14 00:42:00</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2024-01-14 00:42:50</td>\n      <td>2024-01-14 00:44:30</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2024-01-14 00:47:30</td>\n      <td>2024-01-14 00:51:30</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2024-01-14 00:54:40</td>\n      <td>2024-01-14 00:57:30</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2024-01-14 01:00:50</td>\n      <td>2024-01-14 01:01:10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}