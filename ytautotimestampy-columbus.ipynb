{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7321687,"sourceType":"datasetVersion","datasetId":4249023},{"sourceId":7390759,"sourceType":"datasetVersion","datasetId":4296369}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install yt-dlp spleeter -q","metadata":{"_uuid":"874b103f-5550-4ad2-8d22-73e8e98eb196","_cell_guid":"a1625bc1-c21b-4496-b0d2-8f1fc3d19c74","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport re\nimport subprocess\nimport contextlib\nimport logging\nfrom functools import wraps\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nimport librosa\nimport yt_dlp\nfrom spleeter.separator import Separator\nimport ffmpeg\n\nimport torch\nimport torchaudio\nfrom transformers import AutoModelForAudioClassification, ASTFeatureExtractor","metadata":{"_uuid":"cbc7da9d-ed87-4781-acab-e0f064551462","_cell_guid":"79616bb2-fec4-4c9f-9aed-5d25b8f504ca","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def suppress_output(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        # Redirect stdout and logging to os.devnull\n        with open(os.devnull, 'w') as fnull:\n            with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n                # Configure logging to use a NullHandler\n                null_handler = logging.NullHandler()\n                root_logger = logging.getLogger()\n                original_handlers = root_logger.handlers.copy()\n                root_logger.handlers = [null_handler]\n                try:\n                    result = func(*args, **kwargs)\n                finally:\n                    # Restore the original logging handlers\n                    root_logger.handlers = original_handlers\n        return result\n    return wrapper","metadata":{"_uuid":"885b28b5-a337-4fa9-bb41-b4fef004d71c","_cell_guid":"c0c99f87-bdf4-4466-b5c2-8373f5f03b71","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.632751Z","iopub.execute_input":"2024-01-14T06:58:54.633285Z","iopub.status.idle":"2024-01-14T06:58:54.640060Z","shell.execute_reply.started":"2024-01-14T06:58:54.633258Z","shell.execute_reply":"2024-01-14T06:58:54.639213Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def seconds_to_hh_mm_ss(total_seconds):\n    hours = total_seconds // 3600\n    minutes = (total_seconds % 3600) // 60\n    seconds = total_seconds % 60\n    return f\"{hours:02}:{minutes:02}:{seconds:02}\"","metadata":{"_uuid":"12e3b558-121c-4cb0-95f3-5591dafc6f70","_cell_guid":"b38e8abc-bc2a-40ba-8e41-905f94d0b561","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.643240Z","iopub.execute_input":"2024-01-14T06:58:54.643810Z","iopub.status.idle":"2024-01-14T06:58:54.654046Z","shell.execute_reply.started":"2024-01-14T06:58:54.643776Z","shell.execute_reply":"2024-01-14T06:58:54.653283Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef download_youtube_audio(url):\n    ydl_opts = {\n        'format': 'bestaudio',\n        'format_sort': ['+size'],\n        'outtmpl': '%(id)s.%(ext)s',\n        'postprocessors': [{\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': 'wav',  \n        }]\n    }\n\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n        ydl.download([url])\n        video_info = ydl.extract_info(url, download=False)\n    \n    video_path_local = Path(f\"{video_info['id']}.wav\")\n    \n    return video_path_local","metadata":{"_uuid":"ad6ff837-3a42-4bc1-a820-7eaf465c2a13","_cell_guid":"9492610c-5d60-4032-8a29-ad9730634f86","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.655180Z","iopub.execute_input":"2024-01-14T06:58:54.655764Z","iopub.status.idle":"2024-01-14T06:58:54.664599Z","shell.execute_reply.started":"2024-01-14T06:58:54.655730Z","shell.execute_reply":"2024-01-14T06:58:54.663778Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef slice_wav_by_length(input_file, outfile_name_pattern, desired_length=600):\n    # FFmpeg command to split the WAV file into 10-minute segments\n    command = [\n        'ffmpeg',\n        '-hide_banner',  # Added to hide FFmpeg banner\n        '-loglevel', 'error',  # Set log level to error\n        '-i', input_file,\n        '-f', 'segment',\n        '-segment_time', str(desired_length),\n        '-c', 'copy',\n        f\"{outfile_name_pattern}%03d.wav\"\n    ]\n\n    # Run the FFmpeg command\n    subprocess.run(command)","metadata":{"_uuid":"3bdcb9b9-b27e-4e95-9d82-24f66773eb52","_cell_guid":"5c95b893-79e4-43d8-932c-1552c2ff05e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.665641Z","iopub.execute_input":"2024-01-14T06:58:54.665930Z","iopub.status.idle":"2024-01-14T06:58:54.677347Z","shell.execute_reply.started":"2024-01-14T06:58:54.665906Z","shell.execute_reply":"2024-01-14T06:58:54.676622Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef seperate_vocal_and_accompanies(separator, output_paths):\n    output_directory = 'output'\n    os.makedirs(output_directory, exist_ok=True)\n    \n    for file_path in tqdm(output_paths, desc=\"Processing files\"):\n        output_file_path = os.path.join(output_directory, os.path.basename(file_path))\n        separator.separate_to_file(file_path, output_file_path)","metadata":{"_uuid":"a96c161d-9c80-4e16-93f5-ed24a729c206","_cell_guid":"f3660bd1-60de-4330-9e3f-baf6adf3de91","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.678150Z","iopub.execute_input":"2024-01-14T06:58:54.678405Z","iopub.status.idle":"2024-01-14T06:58:54.688230Z","shell.execute_reply.started":"2024-01-14T06:58:54.678383Z","shell.execute_reply":"2024-01-14T06:58:54.687478Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_filepaths_with_string_and_extension(\n    root_directory='.', target_string='', extension=''):\n    return sorted([os.path.abspath(os.path.join(root, file)) \n         for root, _, files in os.walk(root_directory)\n         for file in files \n         if target_string in file and (not extension or file.endswith(extension))]\n    )","metadata":{"_uuid":"59c4f791-3aec-43c1-b348-97b2425a6aa0","_cell_guid":"bfb39bec-3dff-4d7a-a766-2b5a443b0158","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-01-14T06:58:54.689359Z","iopub.execute_input":"2024-01-14T06:58:54.689670Z","iopub.status.idle":"2024-01-14T06:58:54.697753Z","shell.execute_reply.started":"2024-01-14T06:58:54.689645Z","shell.execute_reply":"2024-01-14T06:58:54.696956Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def load_and_slice_audio(vocal_paths, slice_duration=10):\n    all_samples = []\n    all_sampling_rates = []\n\n    for path in tqdm(vocal_paths):\n        waveform, sampling_rate = torchaudio.load(path)\n        waveform = waveform.squeeze().numpy()\n\n        num_slices = waveform.shape[-1] // (sampling_rate * slice_duration)\n\n        samples = [\n            torch.from_numpy(\n                waveform[:, i * sampling_rate * slice_duration : (i + 1) * sampling_rate * slice_duration]\n            )\n            for i in range(num_slices)\n        ]\n\n        all_samples.extend(samples)\n        all_sampling_rates.extend([sampling_rate] * num_slices)\n\n    return all_samples, all_sampling_rates","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.700845Z","iopub.execute_input":"2024-01-14T06:58:58.701384Z","iopub.status.idle":"2024-01-14T06:58:58.708135Z","shell.execute_reply.started":"2024-01-14T06:58:58.701358Z","shell.execute_reply":"2024-01-14T06:58:58.707192Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def get_common_sampling_rate(sampling_rates):\n    if len(set(sampling_rates)) == 1:\n        return int(sampling_rates[0])\n    else:\n        raise ValueError(\"All sampling rates should be the same.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.709425Z","iopub.execute_input":"2024-01-14T06:58:58.710110Z","iopub.status.idle":"2024-01-14T06:58:58.718797Z","shell.execute_reply.started":"2024-01-14T06:58:58.710076Z","shell.execute_reply":"2024-01-14T06:58:58.717879Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def predict_samples(model, feature_extractor, monofied_samples, sampling_rate, device):\n    result = []\n\n    for i, sample in tqdm(enumerate(monofied_samples), total=len(monofied_samples), desc=\"Processing samples\"):\n        inputs = feature_extractor(\n            sample, feature_size=2, sampling_rate=sampling_rate, \n            padding=\"max_length\", return_tensors=\"pt\"\n        )\n        \n        input_values = inputs.input_values.to(device)\n\n        with torch.no_grad():\n            outputs = model(input_values)\n            predicted_labels = model.config.id2label[outputs.logits.argmax(-1).item()]\n            result.append([i, predicted_labels])\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-01-14T07:21:07.334217Z","iopub.execute_input":"2024-01-14T07:21:07.334874Z","iopub.status.idle":"2024-01-14T07:21:07.341556Z","shell.execute_reply.started":"2024-01-14T07:21:07.334832Z","shell.execute_reply":"2024-01-14T07:21:07.340633Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def create_dataframe(predictions, time_window_length):\n    df = pd.DataFrame(predictions, columns=['index', 'class'])\n    df['start'] = df['index'].apply(lambda x: seconds_to_hh_mm_ss(x*time_window_length))\n    df['end'] = df['index'].apply(lambda x: seconds_to_hh_mm_ss((x+1)*time_window_length))\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-01-14T07:22:52.714716Z","iopub.execute_input":"2024-01-14T07:22:52.715056Z","iopub.status.idle":"2024-01-14T07:22:52.720767Z","shell.execute_reply.started":"2024-01-14T07:22:52.715031Z","shell.execute_reply":"2024-01-14T07:22:52.719744Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def audio_analyzer(file_paths, model, device, slice_duration):\n    sliced_samples, sampling_rates = load_and_slice_audio(file_paths, slice_duration)\n    monofied_samples = [torch.mean(x, dim=0) for x in sliced_samples]\n    sampling_rate = get_common_sampling_rate(sampling_rates)\n\n    feature_extractor = ASTFeatureExtractor(\n        sampling_rate=sampling_rate, do_normalize=True\n    )\n\n    predictions = predict_samples(\n        model, feature_extractor, monofied_samples, sampling_rate, device\n    )\n\n    result_df = create_dataframe(predictions, time_window_length=slice_duration)\n\n    return result_df","metadata":{"execution":{"iopub.status.busy":"2024-01-14T07:37:39.397405Z","iopub.execute_input":"2024-01-14T07:37:39.398155Z","iopub.status.idle":"2024-01-14T07:37:39.404034Z","shell.execute_reply.started":"2024-01-14T07:37:39.398121Z","shell.execute_reply":"2024-01-14T07:37:39.403100Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"def class_manipulator(input_df):\n    # Create a copy of the input DataFrame to avoid modifying the original\n    df = input_df.copy()\n\n    # Binarize the 'class' column\n    df['binarized_class'] = df['class'].apply(\n        lambda x: 0 if (x in ['Speech', 'Music', 'Tick', 'Clicking', 'Silence', 'Whistling']) else 1\n    )\n\n    # Create the 'group' column\n    df['group'] = (df['binarized_class'] != df['binarized_class'].shift()).cumsum()\n\n    # Group the DataFrame by the new 'group' column\n    grouped_df = df.groupby(['binarized_class', 'group']).agg(\n        start=('start', 'first'),\n        end=('end', 'last'),\n        class_value=('class', 'first')\n    ).reset_index(drop=True)\n\n    # Filter out unwanted classes and sort by 'start'\n    intermediate_df = grouped_df[\n        ~grouped_df['class_value'].isin(['Speech', 'Music', 'Tick', 'Clicking', 'Silence'])\n    ].sort_values('start').reset_index(drop=True)\n\n    return intermediate_df","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.753946Z","iopub.execute_input":"2024-01-14T06:58:58.754204Z","iopub.status.idle":"2024-01-14T06:58:58.763001Z","shell.execute_reply.started":"2024-01-14T06:58:58.754181Z","shell.execute_reply":"2024-01-14T06:58:58.762222Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def group_same_songs(input_df, interval_threshold, duration_threshold):\n    \n    df = input_df.copy()\n\n    # Convert 'start' and 'end' columns to datetime\n    df['start'] = pd.to_datetime(df['start'])\n    df['end'] = pd.to_datetime(df['end'])\n\n    # Create a new column 'group' and initialize with 0\n    df['group'] = 0\n\n    # Iterate through rows and update the 'group' column based on the specified threshold\n    for i in range(1, len(df)):\n        if (df['start'][i] - df['end'][i - 1]).total_seconds() <= interval_threshold:\n            df.at[i, 'group'] = df.at[i - 1, 'group']\n        else:\n            df.at[i, 'group'] = df.at[i - 1, 'group'] + 1\n\n    # Group by 'group' column\n    grouped_df = df.groupby('group')\n\n    # Iterate through groups and drop if the total duration is less than 30 seconds\n    for group, group_df in grouped_df:\n        duration = (group_df['end'].max() - group_df['start'].min()).total_seconds()\n        if duration < duration_threshold:\n            df = df[df['group'] != group]\n\n    # Drop the 'class_value' column\n    df = df.drop(columns=['class_value'])\n\n    # Group by 'group' column and aggregate 'start' and 'end' columns\n    df = df.groupby('group').agg({'start':'first', 'end':'last'})\n\n    return df\n","metadata":{"execution":{"iopub.status.busy":"2024-01-14T06:58:58.764060Z","iopub.execute_input":"2024-01-14T06:58:58.764321Z","iopub.status.idle":"2024-01-14T06:58:58.777035Z","shell.execute_reply.started":"2024-01-14T06:58:58.764291Z","shell.execute_reply":"2024-01-14T06:58:58.776226Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"!rm -rf ./output\n\noutput_filename_pattern = 'leona'\nroot_dir = '.'  \nyoutube_url = 'https://www.youtube.com/watch?v=hYXjZJPZxtU'\n\nseparator = Separator(\"spleeter:2stems\")\n\nslice_wav_by_length(download_youtube_audio(youtube_url), output_filename_pattern)\n\nwav_slice_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = output_filename_pattern, extension='wav'\n)\n\nseperate_vocal_and_accompanies(separator, wav_slice_paths)\n\naccompanies_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'accompaniment', extension='wav'\n)\n\nvocal_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'vocal', extension='wav'\n)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel = AutoModelForAudioClassification.from_pretrained(\n    \"MIT/ast-finetuned-audioset-10-10-0.4593\").to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T07:39:50.612696Z","iopub.execute_input":"2024-01-14T07:39:50.613103Z","iopub.status.idle":"2024-01-14T07:41:40.417376Z","shell.execute_reply.started":"2024-01-14T07:39:50.613076Z","shell.execute_reply":"2024-01-14T07:41:40.416455Z"},"trusted":true},"execution_count":91,"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing files:   0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92f5933414dd439f92c83f5b84170093"}},"metadata":{}},{"name":"stdout","text":"INFO:spleeter:File output/leona000.wav/leona000/vocals.wav written succesfully\nINFO:spleeter:File output/leona000.wav/leona000/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona001.wav/leona001/vocals.wav written succesfully\nINFO:spleeter:File output/leona001.wav/leona001/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona002.wav/leona002/vocals.wav written succesfully\nINFO:spleeter:File output/leona002.wav/leona002/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona003.wav/leona003/vocals.wav written succesfully\nINFO:spleeter:File output/leona003.wav/leona003/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona004.wav/leona004/vocals.wav written succesfully\nINFO:spleeter:File output/leona004.wav/leona004/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona005.wav/leona005/vocals.wav written succesfully\nINFO:spleeter:File output/leona005.wav/leona005/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona006.wav/leona006/vocals.wav written succesfully\nINFO:spleeter:File output/leona006.wav/leona006/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona007.wav/leona007/vocals.wav written succesfully\nINFO:spleeter:File output/leona007.wav/leona007/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona008.wav/leona008/vocals.wav written succesfully\nINFO:spleeter:File output/leona008.wav/leona008/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona009.wav/leona009/vocals.wav written succesfully\nINFO:spleeter:File output/leona009.wav/leona009/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona010.wav/leona010/vocals.wav written succesfully\nINFO:spleeter:File output/leona010.wav/leona010/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona011.wav/leona011/vocals.wav written succesfully\nINFO:spleeter:File output/leona011.wav/leona011/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona012.wav/leona012/vocals.wav written succesfully\nINFO:spleeter:File output/leona012.wav/leona012/accompaniment.wav written succesfully\nINFO:spleeter:File output/leona013.wav/leona013/vocals.wav written succesfully\nINFO:spleeter:File output/leona013.wav/leona013/accompaniment.wav written succesfully\n","output_type":"stream"}]},{"cell_type":"code","source":"result_vocal = audio_analyzer(vocal_paths, model, device, slice_duration=5)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T07:41:40.420271Z","iopub.execute_input":"2024-01-14T07:41:40.420770Z","iopub.status.idle":"2024-01-14T07:43:39.556477Z","shell.execute_reply.started":"2024-01-14T07:41:40.420717Z","shell.execute_reply":"2024-01-14T07:43:39.555633Z"},"trusted":true},"execution_count":92,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/14 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9892cf3532db4b6faf08a0f1e24fde85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing samples:   0%|          | 0/1593 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"257994e1be344a16a7efe0b862d25b72"}},"metadata":{}}]},{"cell_type":"code","source":"group_same_songs(\n    class_manipulator(result_vocal),\n    interval_threshold=30, duration_threshold=30\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-14T07:43:39.559340Z","iopub.execute_input":"2024-01-14T07:43:39.559624Z","iopub.status.idle":"2024-01-14T07:43:39.684361Z","shell.execute_reply.started":"2024-01-14T07:43:39.559598Z","shell.execute_reply":"2024-01-14T07:43:39.683476Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"                    start                 end\ngroup                                        \n1     2024-01-14 00:01:15 2024-01-14 00:02:50\n3     2024-01-14 00:05:35 2024-01-14 00:09:05\n4     2024-01-14 00:09:40 2024-01-14 00:14:20\n6     2024-01-14 00:16:30 2024-01-14 00:21:05\n8     2024-01-14 00:31:00 2024-01-14 00:32:10\n9     2024-01-14 00:32:55 2024-01-14 00:34:45\n10    2024-01-14 00:35:45 2024-01-14 00:40:50\n11    2024-01-14 00:42:10 2024-01-14 00:45:35\n12    2024-01-14 00:49:15 2024-01-14 00:52:00\n13    2024-01-14 00:55:00 2024-01-14 00:58:45\n15    2024-01-14 01:01:15 2024-01-14 01:04:45\n16    2024-01-14 01:05:40 2024-01-14 01:10:25\n17    2024-01-14 01:12:35 2024-01-14 01:16:10\n19    2024-01-14 01:23:40 2024-01-14 01:27:55\n22    2024-01-14 01:30:45 2024-01-14 01:39:45\n26    2024-01-14 01:44:20 2024-01-14 01:52:25\n27    2024-01-14 01:53:15 2024-01-14 01:59:15\n28    2024-01-14 02:00:05 2024-01-14 02:01:00","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n    <tr>\n      <th>group</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>2024-01-14 00:01:15</td>\n      <td>2024-01-14 00:02:50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-01-14 00:05:35</td>\n      <td>2024-01-14 00:09:05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-01-14 00:09:40</td>\n      <td>2024-01-14 00:14:20</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2024-01-14 00:16:30</td>\n      <td>2024-01-14 00:21:05</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2024-01-14 00:31:00</td>\n      <td>2024-01-14 00:32:10</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2024-01-14 00:32:55</td>\n      <td>2024-01-14 00:34:45</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2024-01-14 00:35:45</td>\n      <td>2024-01-14 00:40:50</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2024-01-14 00:42:10</td>\n      <td>2024-01-14 00:45:35</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2024-01-14 00:49:15</td>\n      <td>2024-01-14 00:52:00</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2024-01-14 00:55:00</td>\n      <td>2024-01-14 00:58:45</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2024-01-14 01:01:15</td>\n      <td>2024-01-14 01:04:45</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2024-01-14 01:05:40</td>\n      <td>2024-01-14 01:10:25</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2024-01-14 01:12:35</td>\n      <td>2024-01-14 01:16:10</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2024-01-14 01:23:40</td>\n      <td>2024-01-14 01:27:55</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>2024-01-14 01:30:45</td>\n      <td>2024-01-14 01:39:45</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2024-01-14 01:44:20</td>\n      <td>2024-01-14 01:52:25</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>2024-01-14 01:53:15</td>\n      <td>2024-01-14 01:59:15</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>2024-01-14 02:00:05</td>\n      <td>2024-01-14 02:01:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}