{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7321687,"sourceType":"datasetVersion","datasetId":4249023},{"sourceId":7390759,"sourceType":"datasetVersion","datasetId":4296369}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install yt-dlp spleeter -q","metadata":{"_uuid":"874b103f-5550-4ad2-8d22-73e8e98eb196","_cell_guid":"a1625bc1-c21b-4496-b0d2-8f1fc3d19c74","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-01T20:09:46.995480Z","iopub.execute_input":"2024-03-01T20:09:46.995811Z","iopub.status.idle":"2024-03-01T20:11:06.943378Z","shell.execute_reply.started":"2024-03-01T20:09:46.995782Z","shell.execute_reply":"2024-03-01T20:11:06.942238Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyter-server~=1.16, but you have jupyter-server 2.12.1 which is incompatible.\nbeatrix-jupyterlab 2023.814.150030 requires jupyterlab~=3.4, but you have jupyterlab 4.0.5 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.19.6 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask 2023.12.0 requires click>=8.1, but you have click 7.1.2 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndistributed 2023.12.0 requires click>=8.0, but you have click 7.1.2 which is incompatible.\nfiona 1.9.5 requires click~=8.0, but you have click 7.1.2 which is incompatible.\nfitter 1.6.0 requires click<9.0.0,>=8.1.6, but you have click 7.1.2 which is incompatible.\nfitter 1.6.0 requires pandas<3.0.0,>=2.0.3, but you have pandas 1.5.3 which is incompatible.\nflask 3.0.0 requires click>=8.1.3, but you have click 7.1.2 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.12.2 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-pubsub 2.18.3 requires grpcio<2.0dev,>=1.51.3, but you have grpcio 1.51.1 which is incompatible.\nkfp 2.0.1 requires click<9,>=8.0.0, but you have click 7.1.2 which is incompatible.\nkfp 2.0.1 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nonnx 1.15.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.4 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.5.0 requires tensorflow~=2.13.0, but you have tensorflow 2.9.3 which is incompatible.\ntensorflow-serving-api 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.13.0 requires tensorflow<3,>=2.13.0, but you have tensorflow 2.9.3 which is incompatible.\ntensorflow-text 2.13.0 requires tensorflow<2.14,>=2.13.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.9.3 which is incompatible.\ntensorflowjs 4.14.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\ntensorflowjs 4.14.0 requires tensorflow<3,>=2.13.0, but you have tensorflow 2.9.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# External libraries\nimport os\nimport re\nimport subprocess\nimport contextlib\nimport logging\nfrom functools import wraps\nfrom pathlib import Path\n\n# Data manipulation and analysis\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\n# Machine learning and data processing\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\n# Visualization\nimport matplotlib.pyplot as plt\n\n# Audio processing and analysis\nimport librosa\nimport yt_dlp\nfrom spleeter.separator import Separator\nimport ffmpeg\nimport torchaudio\n\n# Deep learning\nimport torch\nfrom transformers import AutoModelForAudioClassification, ASTFeatureExtractor","metadata":{"_uuid":"cbc7da9d-ed87-4781-acab-e0f064551462","_cell_guid":"79616bb2-fec4-4c9f-9aed-5d25b8f504ca","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-01T20:11:06.945565Z","iopub.execute_input":"2024-03-01T20:11:06.945884Z","iopub.status.idle":"2024-03-01T20:11:17.762427Z","shell.execute_reply.started":"2024-03-01T20:11:06.945856Z","shell.execute_reply":"2024-03-01T20:11:17.761615Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"def suppress_output(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        # Redirect stdout and logging to os.devnull\n        with open(os.devnull, 'w') as fnull:\n            with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n                # Configure logging to use a NullHandler\n                null_handler = logging.NullHandler()\n                root_logger = logging.getLogger()\n                original_handlers = root_logger.handlers.copy()\n                root_logger.handlers = [null_handler]\n                try:\n                    result = func(*args, **kwargs)\n                finally:\n                    # Restore the original logging handlers\n                    root_logger.handlers = original_handlers\n        return result\n    return wrapper","metadata":{"_uuid":"885b28b5-a337-4fa9-bb41-b4fef004d71c","_cell_guid":"c0c99f87-bdf4-4466-b5c2-8373f5f03b71","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-01T20:11:17.763899Z","iopub.execute_input":"2024-03-01T20:11:17.764648Z","iopub.status.idle":"2024-03-01T20:11:17.773175Z","shell.execute_reply.started":"2024-03-01T20:11:17.764613Z","shell.execute_reply":"2024-03-01T20:11:17.772205Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef download_youtube_audio(url):\n    ydl_opts = {\n        'format': 'bestaudio',\n        'format_sort': ['+size'],\n        'outtmpl': '%(id)s.%(ext)s',\n        'postprocessors': [{\n            'key': 'FFmpegExtractAudio',\n            'preferredcodec': 'wav',  \n        }]\n    }\n\n    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n        ydl.download([url])\n        video_info = ydl.extract_info(url, download=False)\n    \n    video_path_local = Path(f\"{video_info['id']}.wav\")\n    \n    return video_path_local","metadata":{"_uuid":"ad6ff837-3a42-4bc1-a820-7eaf465c2a13","_cell_guid":"9492610c-5d60-4032-8a29-ad9730634f86","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-01T20:11:17.775527Z","iopub.execute_input":"2024-03-01T20:11:17.775826Z","iopub.status.idle":"2024-03-01T20:11:17.792608Z","shell.execute_reply.started":"2024-03-01T20:11:17.775802Z","shell.execute_reply":"2024-03-01T20:11:17.791786Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef slice_wav_by_length(input_file, outfile_name_pattern, desired_length=600):\n    # FFmpeg command to split the WAV file into 10-minute segments\n    command = [\n        'ffmpeg',\n        '-hide_banner',  # Added to hide FFmpeg banner\n        '-loglevel', 'error',  # Set log level to error\n        '-i', input_file,\n        '-f', 'segment',\n        '-segment_time', str(desired_length),\n        '-c', 'copy',\n        f\"{outfile_name_pattern}%03d.wav\"\n    ]\n\n    # Run the FFmpeg command\n    subprocess.run(command)","metadata":{"_uuid":"3bdcb9b9-b27e-4e95-9d82-24f66773eb52","_cell_guid":"5c95b893-79e4-43d8-932c-1552c2ff05e3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-01T20:11:17.793729Z","iopub.execute_input":"2024-03-01T20:11:17.794000Z","iopub.status.idle":"2024-03-01T20:11:17.803806Z","shell.execute_reply.started":"2024-03-01T20:11:17.793977Z","shell.execute_reply":"2024-03-01T20:11:17.802861Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"@suppress_output\ndef seperate_vocal_and_accompanies(separator, output_paths):\n    output_directory = 'output'\n    os.makedirs(output_directory, exist_ok=True)\n    \n    for file_path in tqdm(output_paths, desc=\"Processing files\"):\n        output_file_path = os.path.join(output_directory, os.path.basename(file_path))\n        separator.separate_to_file(file_path, output_file_path)","metadata":{"_uuid":"a96c161d-9c80-4e16-93f5-ed24a729c206","_cell_guid":"f3660bd1-60de-4330-9e3f-baf6adf3de91","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-01T20:11:17.805142Z","iopub.execute_input":"2024-03-01T20:11:17.805514Z","iopub.status.idle":"2024-03-01T20:11:17.817669Z","shell.execute_reply.started":"2024-03-01T20:11:17.805480Z","shell.execute_reply":"2024-03-01T20:11:17.816760Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_filepaths_with_string_and_extension(\n    root_directory='.', target_string='', extension=''):\n    return sorted([os.path.abspath(os.path.join(root, file)) \n         for root, _, files in os.walk(root_directory)\n         for file in files \n         if target_string in file and (not extension or file.endswith(extension))]\n    )","metadata":{"_uuid":"59c4f791-3aec-43c1-b348-97b2425a6aa0","_cell_guid":"bfb39bec-3dff-4d7a-a766-2b5a443b0158","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-03-01T20:11:17.818877Z","iopub.execute_input":"2024-03-01T20:11:17.819153Z","iopub.status.idle":"2024-03-01T20:11:17.827916Z","shell.execute_reply.started":"2024-03-01T20:11:17.819130Z","shell.execute_reply":"2024-03-01T20:11:17.827027Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def load_and_slice_audio(vocal_paths, slice_duration=10):\n    all_samples = []\n    all_sampling_rates = []\n\n    for path in tqdm(vocal_paths):\n        waveform, sampling_rate = torchaudio.load(path)\n        waveform = waveform.squeeze().numpy()\n\n        num_slices = waveform.shape[-1] // (sampling_rate * slice_duration)\n\n        samples = [\n            torch.from_numpy(\n                waveform[:, i * sampling_rate * slice_duration : (i + 1) * sampling_rate * slice_duration]\n            )\n            for i in range(num_slices)\n        ]\n\n        all_samples.extend(samples)\n        all_sampling_rates.extend([sampling_rate] * num_slices)\n\n    return all_samples, all_sampling_rates","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.828965Z","iopub.execute_input":"2024-03-01T20:11:17.829286Z","iopub.status.idle":"2024-03-01T20:11:17.838145Z","shell.execute_reply.started":"2024-03-01T20:11:17.829252Z","shell.execute_reply":"2024-03-01T20:11:17.837369Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def get_common_sampling_rate(sampling_rates):\n    if len(set(sampling_rates)) == 1:\n        return int(sampling_rates[0])\n    else:\n        raise ValueError(\"All sampling rates should be the same.\")","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.839450Z","iopub.execute_input":"2024-03-01T20:11:17.839757Z","iopub.status.idle":"2024-03-01T20:11:17.849151Z","shell.execute_reply.started":"2024-03-01T20:11:17.839731Z","shell.execute_reply":"2024-03-01T20:11:17.848216Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def predict_samples(model, feature_extractor, monofied_samples, sampling_rate, device):\n    result = []\n    raw_outputs = []\n\n    for i, sample in tqdm(enumerate(monofied_samples), total=len(monofied_samples), desc=\"Processing samples\"):\n        inputs = feature_extractor(\n            sample, feature_size=2, sampling_rate=sampling_rate, \n            padding=\"max_length\", return_tensors=\"pt\"\n        )\n        \n        input_values = inputs.input_values.to(device)\n\n        with torch.no_grad():\n            outputs = model(input_values)\n            predicted_labels = model.config.id2label[outputs.logits.argmax(-1).item()]\n            result.append([i, predicted_labels])\n            raw_outputs.append(outputs)\n\n    return result, raw_outputs","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.853109Z","iopub.execute_input":"2024-03-01T20:11:17.854038Z","iopub.status.idle":"2024-03-01T20:11:17.864132Z","shell.execute_reply.started":"2024-03-01T20:11:17.854007Z","shell.execute_reply":"2024-03-01T20:11:17.863303Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def create_dataframe(predictions, time_window_length):\n    df = pd.DataFrame(predictions, columns=['index', 'class'])\n    df['start'] = df['index'].apply(lambda x: seconds_to_hhmmss(x*time_window_length))\n    df['end'] = df['index'].apply(lambda x: seconds_to_hhmmss((x+1)*time_window_length))\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.865288Z","iopub.execute_input":"2024-03-01T20:11:17.865568Z","iopub.status.idle":"2024-03-01T20:11:17.875048Z","shell.execute_reply.started":"2024-03-01T20:11:17.865544Z","shell.execute_reply":"2024-03-01T20:11:17.874225Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def audio_analyzer(file_paths, model, device, slice_duration):\n    sliced_samples, sampling_rates = load_and_slice_audio(file_paths, slice_duration)\n    monofied_samples = [torch.mean(x, dim=0) for x in sliced_samples]\n    sampling_rate = get_common_sampling_rate(sampling_rates)\n\n    feature_extractor = ASTFeatureExtractor(\n        sampling_rate=sampling_rate, do_normalize=True\n    )\n\n    predictions, raw_outputs = predict_samples(\n        model, feature_extractor, monofied_samples, sampling_rate, device\n    )\n\n    result_df = create_dataframe(predictions, time_window_length=slice_duration)\n\n    return result_df, raw_outputs","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.876052Z","iopub.execute_input":"2024-03-01T20:11:17.876333Z","iopub.status.idle":"2024-03-01T20:11:17.885468Z","shell.execute_reply.started":"2024-03-01T20:11:17.876309Z","shell.execute_reply":"2024-03-01T20:11:17.884621Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def class_manipulator_old(input_df):\n    # Create a copy of the input DataFrame to avoid modifying the original\n    df = input_df.copy()\n\n    # Binarize the 'class' column\n    df['binarized_class'] = df['class'].apply(\n        lambda x: 0 if (x in ['Speech','Tick', 'Clicking', ]) else 1\n    )\n\n    # Create the 'group' column\n    df['group'] = (df['binarized_class'] != df['binarized_class'].shift()).cumsum()\n\n    # Group the DataFrame by the new 'group' column\n    grouped_df = df.groupby(['binarized_class', 'group']).agg(\n        start=('start', 'first'),\n        end=('end', 'last'),\n        class_value=('class', 'first')\n    ).reset_index(drop=True)\n\n    # Filter out unwanted classes and sort by 'start'\n    intermediate_df = grouped_df[\n        ~grouped_df['class_value'].isin(['Speech','Tick', 'Clicking',])\n    ].sort_values('start').reset_index(drop=True)\n\n    return intermediate_df","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.886624Z","iopub.execute_input":"2024-03-01T20:11:17.886919Z","iopub.status.idle":"2024-03-01T20:11:17.895846Z","shell.execute_reply.started":"2024-03-01T20:11:17.886896Z","shell.execute_reply":"2024-03-01T20:11:17.895025Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def class_manipulator(input_df, singing_like_classes):\n    \n    def _get_most_frequent_with_fallback(x):\n        modes = x.mode()\n        if not modes.empty:\n            if any(mode in singing_like_classes for mode in modes):\n                return 'Singing'\n        return None #'Speech'\n    \n    # Create a copy of the input DataFrame to avoid modifying the original\n    df = input_df.copy()\n    \n    # Binarize the 'class' column\n    df['binarized_class'] = df['class'].apply(\n        lambda x : 1 if (x in singing_like_classes) else 0\n    )\n\n    # Create the 'group' column\n    df['group'] = (df['binarized_class'] != df['binarized_class'].shift()).cumsum()\n\n    # Group the DataFrame by the new 'group' column\n    grouped_df = df.groupby(['binarized_class', 'group']).agg(\n        start=('start', 'first'),\n        end=('end', 'last'),\n        class_value=('class', _get_most_frequent_with_fallback) \n    ).reset_index(drop=True).dropna()\n\n    return grouped_df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.896960Z","iopub.execute_input":"2024-03-01T20:11:17.897297Z","iopub.status.idle":"2024-03-01T20:11:17.909365Z","shell.execute_reply.started":"2024-03-01T20:11:17.897263Z","shell.execute_reply":"2024-03-01T20:11:17.908587Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def group_same_songs(input_df, interval_threshold, duration_threshold):\n    \n    df = input_df.copy()\n\n    df['start'] = pd.to_datetime(df['start'])\n    df['end'] = pd.to_datetime(df['end'])\n\n    df['group'] = 0\n\n    for i in range(1, len(df)):\n        if (df['start'][i] - df['end'][i - 1]).total_seconds() <= interval_threshold:\n            df.at[i, 'group'] = df.at[i - 1, 'group']\n        else:\n            df.at[i, 'group'] = df.at[i - 1, 'group'] + 1\n\n    grouped_df = df.groupby('group')\n\n    for group, group_df in grouped_df:\n        duration = (group_df['end'].max() - group_df['start'].min()).total_seconds()\n        if duration < duration_threshold:\n            df = df[df['group'] != group]\n\n    df = df.drop(columns=['class_value'])\n\n    df = df.groupby('group').agg({'start':'first', 'end':'last'})\n\n    df['start'] = df['start'].apply(lambda x:x.strftime('%H:%M:%S'))\n    df['end'] = df['end'].apply(lambda x:x.strftime('%H:%M:%S'))\n    \n    return df.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.910511Z","iopub.execute_input":"2024-03-01T20:11:17.910824Z","iopub.status.idle":"2024-03-01T20:11:17.920451Z","shell.execute_reply.started":"2024-03-01T20:11:17.910801Z","shell.execute_reply":"2024-03-01T20:11:17.919698Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def mfcc_from_accompanies(accompanies_paths, slice_duration=5):\n\n    sliced_samples, sampling_rates = load_and_slice_audio(accompanies_paths, slice_duration)\n    monofied_samples = [torch.mean(x, dim=0) for x in sliced_samples]\n    sampling_rate = get_common_sampling_rate(sampling_rates)\n    mfccs = [librosa.feature.mfcc(y=y.numpy(), sr=sampling_rate, n_mfcc=13) \n             for y in monofied_samples]\n    \n    return mfccs","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.921484Z","iopub.execute_input":"2024-03-01T20:11:17.921755Z","iopub.status.idle":"2024-03-01T20:11:17.935605Z","shell.execute_reply.started":"2024-03-01T20:11:17.921732Z","shell.execute_reply":"2024-03-01T20:11:17.934678Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def cluster_mfccs(mfccs):\n    full_flattens = [x.flatten() for x in mfccs]\n    kmeans = KMeans(n_clusters=2, n_init=2)  # You can choose the number of clusters\n    kmeans.fit(full_flattens)\n    cluster_labels = kmeans.labels_\n\n    indices = np.arange(len(cluster_labels))\n    temp_df = create_dataframe(np.vstack((indices, cluster_labels)).T, time_window_length=5)\n\n    value_counts = temp_df['class'].value_counts()\n    major_value = value_counts.idxmax()\n    minor_value = value_counts.idxmin()\n\n    label_mapping = {major_value: 'Speech', minor_value: 'Singing'}\n    temp_df['class_value'] = temp_df['class'].map(label_mapping)\n\n    return temp_df[temp_df['class_value']=='Singing'].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.936674Z","iopub.execute_input":"2024-03-01T20:11:17.936943Z","iopub.status.idle":"2024-03-01T20:11:17.946056Z","shell.execute_reply.started":"2024-03-01T20:11:17.936919Z","shell.execute_reply":"2024-03-01T20:11:17.945325Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def cluster_mfccs_with_pca(mfccs, visualize=False):\n    # Flatten the MFCCs\n    full_flattens = [x.flatten() for x in mfccs]\n\n    # Apply PCA to reduce dimensionality\n    pca = PCA(n_components=2)\n    reduced_data = pca.fit_transform(full_flattens)\n\n    # Perform KMeans clustering on the reduced data\n    kmeans = KMeans(n_clusters=2, init='k-means++', n_init=2)  \n    kmeans.fit(reduced_data)\n    cluster_labels = kmeans.labels_\n\n    if visualize:# Visualization\n        plt.scatter(reduced_data[:, 0], reduced_data[:, 1], \n                    c=cluster_labels, cmap='viridis', alpha=0.5)\n        plt.xlabel('PCA Component 1')\n        plt.ylabel('PCA Component 2')\n        plt.title('Clustering of MFCCs with PCA')\n        plt.colorbar(label='Cluster')\n        plt.show()\n\n    # Create a DataFrame for analysis\n    indices = np.arange(len(cluster_labels))\n    temp_df = create_dataframe(np.vstack((indices, cluster_labels)).T, time_window_length=5)\n\n    # Analyze the clusters and filter for 'Singing'\n    value_counts = temp_df['class'].value_counts()\n    major_value = value_counts.idxmax()\n    minor_value = value_counts.idxmin()\n\n    label_mapping = {major_value: 'Speech', minor_value: 'Singing'}\n    temp_df['class_value'] = temp_df['class'].map(label_mapping)\n\n    return temp_df[temp_df['class_value']=='Singing'].reset_index(drop=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.947133Z","iopub.execute_input":"2024-03-01T20:11:17.947441Z","iopub.status.idle":"2024-03-01T20:11:17.960961Z","shell.execute_reply.started":"2024-03-01T20:11:17.947410Z","shell.execute_reply":"2024-03-01T20:11:17.960224Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\nimport numpy as np\n\ndef compare_clustering_quality(mfccs, n_clusters=2):\n    # Without PCA\n    kmeans_no_pca = KMeans(n_clusters=n_clusters, n_init=2)\n    kmeans_no_pca.fit(np.vstack([x.flatten() for x in mfccs]))\n    cluster_labels_no_pca = kmeans_no_pca.labels_\n    inertia_no_pca = kmeans_no_pca.inertia_\n    silhouette_score_no_pca = silhouette_score(np.vstack([x.flatten() for x in mfccs]), cluster_labels_no_pca)\n\n    # With PCA\n    pca = PCA(n_components=2)\n    reduced_data = pca.fit_transform(np.vstack([x.flatten() for x in mfccs]))\n\n    kmeans_with_pca = KMeans(n_clusters=n_clusters, n_init=2)\n    kmeans_with_pca.fit(reduced_data)\n    cluster_labels_with_pca = kmeans_with_pca.labels_\n    inertia_with_pca = kmeans_with_pca.inertia_\n    silhouette_score_with_pca = silhouette_score(reduced_data, cluster_labels_with_pca)\n\n    # Print results\n    print(\"Clustering Quality Comparison:\")\n    print(\"Without PCA:\")\n    print(f\"Inertia: {inertia_no_pca}\") #sum of squared distance to center of each sample\n    print(f\"Silhouette Score: {silhouette_score_no_pca}\") \n    # [b] - [a] over\n    # max(mean distance for a sample to its other samples in same cluster [a] or not [b])\n    print(\"With PCA:\")\n    print(f\"Inertia: {inertia_with_pca}\")\n    print(f\"Silhouette Score: {silhouette_score_with_pca}\")\n\n    return (inertia_no_pca, silhouette_score_no_pca), (inertia_with_pca, silhouette_score_with_pca)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.961971Z","iopub.execute_input":"2024-03-01T20:11:17.962269Z","iopub.status.idle":"2024-03-01T20:11:17.975200Z","shell.execute_reply.started":"2024-03-01T20:11:17.962245Z","shell.execute_reply":"2024-03-01T20:11:17.974349Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def seconds_to_hhmmss(total_seconds):\n    m, s = divmod(total_seconds, 60)\n    h, m = divmod(m, 60)\n    return f\"{h:02d}:{m:02d}:{s:02d}\"\n        \ndef hhmmss_to_seconds(hms):\n    h, m, s = map(int, hms.split(':'))\n    return h * 3600 + m * 60 + s","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.976333Z","iopub.execute_input":"2024-03-01T20:11:17.976613Z","iopub.status.idle":"2024-03-01T20:11:17.989426Z","shell.execute_reply.started":"2024-03-01T20:11:17.976589Z","shell.execute_reply":"2024-03-01T20:11:17.988454Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def check_overlap(interval1_start, interval1_end, interval2_start, interval2_end):\n    return (interval1_start <= interval2_end and interval1_end >= interval2_start) or \\\n           (interval2_start <= interval1_end and interval2_end >= interval1_start)\n\ndef filter_redundant_overlaps(unique_overlapping_timestamps):\n    filtered_overlapping_timestamps = [\n        overlap for overlap in unique_overlapping_timestamps\n        if all(\n            not (\n                (overlap['start']) >= (other_overlap['start']) and\n                (overlap['end']) <= (other_overlap['end'])\n            )\n            for other_overlap in unique_overlapping_timestamps\n            if overlap != other_overlap\n        )\n    ]\n    return filtered_overlapping_timestamps\n\ndef merge_overlapping_times_df(df):\n    # Sort the DataFrame by start time\n    df_sorted = df.sort_values(by=['start'])\n\n    merged_times = []\n\n    # Initialize variables to keep track of the current start and end times\n    current_start = df_sorted.iloc[0]['start']\n    current_end = df_sorted.iloc[0]['end']\n\n    # Iterate over the sorted DataFrame\n    for index, row in df_sorted.iloc[1:].iterrows():\n        start = row['start']\n        end = row['end']\n        \n        # Check for overlap\n        if start <= current_end:\n            # Update the current end time if necessary\n            current_end = max(current_end, end)\n        else:\n            # Add the merged time interval to the list and update current start and end times\n            merged_times.append({'start': current_start, 'end': current_end})\n            current_start = start\n            current_end = end\n\n    # Add the last merged time interval\n    merged_times.append({'start': current_start, 'end': current_end})\n    result = pd.DataFrame(merged_times)\n    result['start'] = result['start'].apply(seconds_to_hhmmss)\n    result['end'] = result['end'].apply(seconds_to_hhmmss)\n\n    return result\n\ndef find_and_filter_overlapping_timestamps(accompanies_df, vocal_df):\n    unique_overlapping_timestamps = []\n\n    for _, row1 in accompanies_df.iterrows():\n        for _, row2 in vocal_df.iterrows():\n            start1_seconds = hhmmss_to_seconds(row1['start'])\n            end1_seconds = hhmmss_to_seconds(row1['end'])\n            start2_seconds = hhmmss_to_seconds(row2['start'])\n            end2_seconds = hhmmss_to_seconds(row2['end'])\n\n            # Check for overlap\n            if check_overlap(start1_seconds, end1_seconds, start2_seconds, end2_seconds):\n                overlap_start = min(start1_seconds, start2_seconds)\n                overlap_end = max(end1_seconds, end2_seconds)\n                overlapping_timestamp = {\n                    'start': overlap_start,#seconds_to_hhmmss(overlap_start),\n                    'end': overlap_end#seconds_to_hhmmss(overlap_end)\n                }\n                if overlapping_timestamp not in unique_overlapping_timestamps:\n                    unique_overlapping_timestamps.append(overlapping_timestamp)\n\n    filtered_overlapping_timestamps = filter_redundant_overlaps(\n        unique_overlapping_timestamps\n    )\n\n    merged_result = pd.DataFrame(filtered_overlapping_timestamps)\n\n    return merge_overlapping_times_df(merged_result)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:17.990761Z","iopub.execute_input":"2024-03-01T20:11:17.991054Z","iopub.status.idle":"2024-03-01T20:11:18.005944Z","shell.execute_reply.started":"2024-03-01T20:11:17.991030Z","shell.execute_reply":"2024-03-01T20:11:18.005036Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"!rm -rf ./output\n\noutput_filename_pattern = 'nemo1'\nroot_dir = '.'  \nyoutube_url = 'https://www.youtube.com/watch?v=BQr0IVJEDx8'\n\nseparator = Separator(\"spleeter:2stems\")\n\nslice_wav_by_length(download_youtube_audio(youtube_url), output_filename_pattern)\n\nwav_slice_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = output_filename_pattern, extension='wav'\n)\n\nseperate_vocal_and_accompanies(separator, wav_slice_paths)\n\naccompanies_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'accompaniment', extension='wav'\n)\n\nvocal_paths = get_filepaths_with_string_and_extension(\n    root_dir, target_string = 'vocal', extension='wav'\n)\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel = AutoModelForAudioClassification.from_pretrained(\n    \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:11:18.007497Z","iopub.execute_input":"2024-03-01T20:11:18.007794Z","iopub.status.idle":"2024-03-01T20:13:35.459040Z","shell.execute_reply.started":"2024-03-01T20:11:18.007769Z","shell.execute_reply":"2024-03-01T20:13:35.458121Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing files:   0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2728a71f87254e70abe77f792827106e"}},"metadata":{}},{"name":"stdout","text":"INFO:spleeter:File output/nemo1000.wav/nemo1000/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1000.wav/nemo1000/accompaniment.wav written succesfully\nINFO:spleeter:File output/nemo1001.wav/nemo1001/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1001.wav/nemo1001/accompaniment.wav written succesfully\nINFO:spleeter:File output/nemo1002.wav/nemo1002/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1002.wav/nemo1002/accompaniment.wav written succesfully\nINFO:spleeter:File output/nemo1003.wav/nemo1003/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1003.wav/nemo1003/accompaniment.wav written succesfully\nINFO:spleeter:File output/nemo1004.wav/nemo1004/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1004.wav/nemo1004/accompaniment.wav written succesfully\nINFO:spleeter:File output/nemo1005.wav/nemo1005/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1005.wav/nemo1005/accompaniment.wav written succesfully\nINFO:spleeter:File output/nemo1006.wav/nemo1006/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1006.wav/nemo1006/accompaniment.wav written succesfully\nINFO:spleeter:File output/nemo1007.wav/nemo1007/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1007.wav/nemo1007/accompaniment.wav written succesfully\nINFO:spleeter:File output/nemo1008.wav/nemo1008/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1008.wav/nemo1008/accompaniment.wav written succesfully\nINFO:spleeter:File output/nemo1009.wav/nemo1009/vocals.wav written succesfully\nINFO:spleeter:File output/nemo1009.wav/nemo1009/accompaniment.wav written succesfully\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdac62c886f34400a21a383fe3430117"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"298b3e1e441d4967b2e9a8a53618707e"}},"metadata":{}}]},{"cell_type":"code","source":"result_vocal, raw_outputs = audio_analyzer(\n    vocal_paths, model, device, slice_duration=5\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:13:35.460518Z","iopub.execute_input":"2024-03-01T20:13:35.460835Z","iopub.status.idle":"2024-03-01T20:14:56.814766Z","shell.execute_reply.started":"2024-03-01T20:13:35.460795Z","shell.execute_reply":"2024-03-01T20:14:56.813727Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97fbc157896f424e9af0f46b4f425340"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing samples:   0%|          | 0/1095 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10ba1ecc82544f398492a5d99a52c3ef"}},"metadata":{}}]},{"cell_type":"code","source":"classes = model.config.id2label\nsinging_like_indices = [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 112, 113, 114, 116, 117, 118, 119, 120, 136, 254, 255, 266, 259, 268, 269, 271, 402, 496, 503,523, 526]\nsinging_like_classes = [classes.get(x) for x in singing_like_indices]","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:14:56.816091Z","iopub.execute_input":"2024-03-01T20:14:56.816418Z","iopub.status.idle":"2024-03-01T20:14:56.822386Z","shell.execute_reply.started":"2024-03-01T20:14:56.816392Z","shell.execute_reply":"2024-03-01T20:14:56.821329Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"vocal_result = group_same_songs(\n    class_manipulator(result_vocal, singing_like_classes),\n    interval_threshold=5, duration_threshold=10\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:14:56.823655Z","iopub.execute_input":"2024-03-01T20:14:56.823929Z","iopub.status.idle":"2024-03-01T20:14:56.926882Z","shell.execute_reply.started":"2024-03-01T20:14:56.823905Z","shell.execute_reply":"2024-03-01T20:14:56.926082Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"mfccs = mfcc_from_accompanies(accompanies_paths, slice_duration=5)\naccompanies_based_cluster = cluster_mfccs_with_pca(mfccs)\n\naccompanies_result = group_same_songs(\n    accompanies_based_cluster,\n    interval_threshold=5, duration_threshold=10\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:14:56.928146Z","iopub.execute_input":"2024-03-01T20:14:56.928496Z","iopub.status.idle":"2024-03-01T20:15:47.361796Z","shell.execute_reply.started":"2024-03-01T20:14:56.928469Z","shell.execute_reply":"2024-03-01T20:15:47.360963Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0efa7aa630944b15a393c0eafaa97c80"}},"metadata":{}}]},{"cell_type":"code","source":"higher_probability_timestamps = find_and_filter_overlapping_timestamps(\n    accompanies_result, vocal_result\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:15:47.362894Z","iopub.execute_input":"2024-03-01T20:15:47.363826Z","iopub.status.idle":"2024-03-01T20:15:47.405033Z","shell.execute_reply.started":"2024-03-01T20:15:47.363796Z","shell.execute_reply":"2024-03-01T20:15:47.404054Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"higher_probability_timestamps","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:15:47.409797Z","iopub.execute_input":"2024-03-01T20:15:47.410181Z","iopub.status.idle":"2024-03-01T20:15:47.428939Z","shell.execute_reply.started":"2024-03-01T20:15:47.410136Z","shell.execute_reply":"2024-03-01T20:15:47.427818Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"      start       end\n0  00:10:15  00:14:25\n1  00:18:25  00:22:35\n2  00:23:10  00:26:30\n3  00:34:55  00:39:05\n4  00:46:05  00:49:30\n5  00:54:45  00:57:10\n6  00:59:15  01:03:40\n7  01:03:55  01:07:40\n8  01:11:20  01:14:50\n9  01:18:00  01:22:55","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00:10:15</td>\n      <td>00:14:25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00:18:25</td>\n      <td>00:22:35</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00:23:10</td>\n      <td>00:26:30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00:34:55</td>\n      <td>00:39:05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00:46:05</td>\n      <td>00:49:30</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>00:54:45</td>\n      <td>00:57:10</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>00:59:15</td>\n      <td>01:03:40</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>01:03:55</td>\n      <td>01:07:40</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>01:11:20</td>\n      <td>01:14:50</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>01:18:00</td>\n      <td>01:22:55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(higher_probability_timestamps.to_json())","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:15:47.430211Z","iopub.execute_input":"2024-03-01T20:15:47.430596Z","iopub.status.idle":"2024-03-01T20:15:47.437337Z","shell.execute_reply.started":"2024-03-01T20:15:47.430562Z","shell.execute_reply":"2024-03-01T20:15:47.436296Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"{\"start\":{\"0\":\"00:10:15\",\"1\":\"00:18:25\",\"2\":\"00:23:10\",\"3\":\"00:34:55\",\"4\":\"00:46:05\",\"5\":\"00:54:45\",\"6\":\"00:59:15\",\"7\":\"01:03:55\",\"8\":\"01:11:20\",\"9\":\"01:18:00\"},\"end\":{\"0\":\"00:14:25\",\"1\":\"00:22:35\",\"2\":\"00:26:30\",\"3\":\"00:39:05\",\"4\":\"00:49:30\",\"5\":\"00:57:10\",\"6\":\"01:03:40\",\"7\":\"01:07:40\",\"8\":\"01:14:50\",\"9\":\"01:22:55\"}}\n","output_type":"stream"}]},{"cell_type":"code","source":"def overlap(interval1, interval2):\n    return not (interval1['end'] < interval2['start'] or interval1['start'] > interval2['end'])\n\nnon_overlapping_rows = []\nfor index, row in vocal_result.iterrows():\n    interval = {'start': row['start'], 'end': row['end']}\n    overlaps = False\n    for _, hp_row in higher_probability_timestamps.iterrows():\n        hp_interval = {'start': hp_row['start'], 'end': hp_row['end']}\n        if overlap(interval, hp_interval):\n            overlaps = True\n            break\n    if not overlaps:\n        non_overlapping_rows.append(row)\n        \npossible_a_capella = pd.DataFrame(non_overlapping_rows).reset_index(drop=True)\n\nprint(possible_a_capella.to_json())","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:15:47.438780Z","iopub.execute_input":"2024-03-01T20:15:47.439142Z","iopub.status.idle":"2024-03-01T20:15:47.466030Z","shell.execute_reply.started":"2024-03-01T20:15:47.439109Z","shell.execute_reply":"2024-03-01T20:15:47.464978Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"{\"start\":{\"0\":\"00:08:30\",\"1\":\"00:31:20\",\"2\":\"00:32:55\",\"3\":\"01:08:35\",\"4\":\"01:15:45\",\"5\":\"01:30:45\"},\"end\":{\"0\":\"00:08:40\",\"1\":\"00:31:30\",\"2\":\"00:33:05\",\"3\":\"01:08:55\",\"4\":\"01:15:55\",\"5\":\"01:30:55\"}}\n","output_type":"stream"}]},{"cell_type":"code","source":"possible_a_capella","metadata":{"execution":{"iopub.status.busy":"2024-03-01T20:15:47.467379Z","iopub.execute_input":"2024-03-01T20:15:47.468027Z","iopub.status.idle":"2024-03-01T20:15:47.481557Z","shell.execute_reply.started":"2024-03-01T20:15:47.467989Z","shell.execute_reply":"2024-03-01T20:15:47.480591Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"      start       end\n0  00:08:30  00:08:40\n1  00:31:20  00:31:30\n2  00:32:55  00:33:05\n3  01:08:35  01:08:55\n4  01:15:45  01:15:55\n5  01:30:45  01:30:55","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start</th>\n      <th>end</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00:08:30</td>\n      <td>00:08:40</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00:31:20</td>\n      <td>00:31:30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00:32:55</td>\n      <td>00:33:05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01:08:35</td>\n      <td>01:08:55</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01:15:45</td>\n      <td>01:15:55</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>01:30:45</td>\n      <td>01:30:55</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}